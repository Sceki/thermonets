{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feed-forward training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vf/cj60m8k162316snsvmjw65280000gp/T/ipykernel_43019/3354738791.py:5: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import thermonets\n",
    "import torch\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database columns are: Index(['day', 'month', 'year', 'hour', 'minute', 'second', 'microsecond',\n",
      "       'alt [km]', 'lat [deg]', 'lon [deg]', 'f107A', 'f107', 'ap',\n",
      "       'wind zonal [m/s]', 'wind meridional [m/s]', 'density [kg/m^3]'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#I load the data generated via `/scripts/generate_nrlmsise00_db.py` and print the columns\n",
    "df=pd.read_csv('../dbs/nrlmsise00_db.txt',delimiter=',',skipinitialspace=True)\n",
    "print(f'Database columns are: {df.columns}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>second</th>\n",
       "      <th>microsecond</th>\n",
       "      <th>alt [km]</th>\n",
       "      <th>lat [deg]</th>\n",
       "      <th>lon [deg]</th>\n",
       "      <th>f107A</th>\n",
       "      <th>f107</th>\n",
       "      <th>ap</th>\n",
       "      <th>wind zonal [m/s]</th>\n",
       "      <th>wind meridional [m/s]</th>\n",
       "      <th>density [kg/m^3]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>999800.000000</td>\n",
       "      <td>999800.000000</td>\n",
       "      <td>999800.000000</td>\n",
       "      <td>999800.000000</td>\n",
       "      <td>999800.000000</td>\n",
       "      <td>999800.000000</td>\n",
       "      <td>999800.000000</td>\n",
       "      <td>999800.000000</td>\n",
       "      <td>999800.000000</td>\n",
       "      <td>999800.000000</td>\n",
       "      <td>999800.000000</td>\n",
       "      <td>999800.000000</td>\n",
       "      <td>999800.000000</td>\n",
       "      <td>999800.000000</td>\n",
       "      <td>999800.000000</td>\n",
       "      <td>9.998000e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>15.754151</td>\n",
       "      <td>6.531806</td>\n",
       "      <td>2015.586617</td>\n",
       "      <td>11.585017</td>\n",
       "      <td>29.184137</td>\n",
       "      <td>29.379876</td>\n",
       "      <td>505858.019204</td>\n",
       "      <td>342.516651</td>\n",
       "      <td>0.001633</td>\n",
       "      <td>179.979632</td>\n",
       "      <td>96.727886</td>\n",
       "      <td>96.581916</td>\n",
       "      <td>7.836767</td>\n",
       "      <td>-2.879626</td>\n",
       "      <td>-0.494954</td>\n",
       "      <td>1.205831e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.866384</td>\n",
       "      <td>3.453424</td>\n",
       "      <td>4.008351</td>\n",
       "      <td>6.911738</td>\n",
       "      <td>17.378472</td>\n",
       "      <td>17.449451</td>\n",
       "      <td>287608.595307</td>\n",
       "      <td>135.816963</td>\n",
       "      <td>40.109198</td>\n",
       "      <td>104.967288</td>\n",
       "      <td>26.657874</td>\n",
       "      <td>29.821355</td>\n",
       "      <td>7.925704</td>\n",
       "      <td>73.198546</td>\n",
       "      <td>56.008426</td>\n",
       "      <td>2.411612e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2009.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>158.489319</td>\n",
       "      <td>-90.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-276.078125</td>\n",
       "      <td>-311.510712</td>\n",
       "      <td>2.162184e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2012.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>255869.000000</td>\n",
       "      <td>223.876192</td>\n",
       "      <td>-31.007583</td>\n",
       "      <td>87.272727</td>\n",
       "      <td>72.100000</td>\n",
       "      <td>71.900000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>-60.091662</td>\n",
       "      <td>-29.850723</td>\n",
       "      <td>5.470582e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>16.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2016.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>507462.000000</td>\n",
       "      <td>316.235464</td>\n",
       "      <td>0.578755</td>\n",
       "      <td>178.181818</td>\n",
       "      <td>84.900000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>-7.904188</td>\n",
       "      <td>1.651052</td>\n",
       "      <td>8.843380e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>23.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>2019.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>754783.000000</td>\n",
       "      <td>446.691766</td>\n",
       "      <td>31.007583</td>\n",
       "      <td>269.090909</td>\n",
       "      <td>119.400000</td>\n",
       "      <td>114.500000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>54.363447</td>\n",
       "      <td>31.471937</td>\n",
       "      <td>1.026746e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>31.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2022.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>999964.000000</td>\n",
       "      <td>630.957344</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>161.100000</td>\n",
       "      <td>262.000000</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>316.930359</td>\n",
       "      <td>267.179596</td>\n",
       "      <td>1.720909e-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 day          month           year           hour  \\\n",
       "count  999800.000000  999800.000000  999800.000000  999800.000000   \n",
       "mean       15.754151       6.531806    2015.586617      11.585017   \n",
       "std         8.866384       3.453424       4.008351       6.911738   \n",
       "min         1.000000       1.000000    2009.000000       0.000000   \n",
       "25%         8.000000       4.000000    2012.000000       6.000000   \n",
       "50%        16.000000       7.000000    2016.000000      12.000000   \n",
       "75%        23.000000      10.000000    2019.000000      18.000000   \n",
       "max        31.000000      12.000000    2022.000000      23.000000   \n",
       "\n",
       "              minute         second    microsecond       alt [km]  \\\n",
       "count  999800.000000  999800.000000  999800.000000  999800.000000   \n",
       "mean       29.184137      29.379876  505858.019204     342.516651   \n",
       "std        17.378472      17.449451  287608.595307     135.816963   \n",
       "min         0.000000       0.000000      85.000000     158.489319   \n",
       "25%        14.000000      14.000000  255869.000000     223.876192   \n",
       "50%        29.000000      29.000000  507462.000000     316.235464   \n",
       "75%        44.000000      45.000000  754783.000000     446.691766   \n",
       "max        59.000000      59.000000  999964.000000     630.957344   \n",
       "\n",
       "           lat [deg]      lon [deg]          f107A           f107  \\\n",
       "count  999800.000000  999800.000000  999800.000000  999800.000000   \n",
       "mean        0.001633     179.979632      96.727886      96.581916   \n",
       "std        40.109198     104.967288      26.657874      29.821355   \n",
       "min       -90.000000       0.000000      67.100000      64.000000   \n",
       "25%       -31.007583      87.272727      72.100000      71.900000   \n",
       "50%         0.578755     178.181818      84.900000      85.000000   \n",
       "75%        31.007583     269.090909     119.400000     114.500000   \n",
       "max        90.000000     360.000000     161.100000     262.000000   \n",
       "\n",
       "                  ap  wind zonal [m/s]  wind meridional [m/s]  \\\n",
       "count  999800.000000     999800.000000          999800.000000   \n",
       "mean        7.836767         -2.879626              -0.494954   \n",
       "std         7.925704         73.198546              56.008426   \n",
       "min         0.000000       -276.078125            -311.510712   \n",
       "25%         3.000000        -60.091662             -29.850723   \n",
       "50%         5.000000         -7.904188               1.651052   \n",
       "75%        10.000000         54.363447              31.471937   \n",
       "max       108.000000        316.930359             267.179596   \n",
       "\n",
       "       density [kg/m^3]  \n",
       "count      9.998000e+05  \n",
       "mean       1.205831e-10  \n",
       "std        2.411612e-10  \n",
       "min        2.162184e-15  \n",
       "25%        5.470582e-13  \n",
       "50%        8.843380e-12  \n",
       "75%        1.026746e-10  \n",
       "max        1.720909e-09  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#some descriptive statistics:\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting features of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seconds in day min and max:\n",
      "86381.805516 5.198408\n",
      "day of the year min and max:\n",
      "365.0 1.0\n"
     ]
    }
   ],
   "source": [
    "#I now construct the day of the year and seconds in day:\n",
    "years=df['year'].values\n",
    "months=df['month'].values\n",
    "days=df['day'].values\n",
    "hours=df['hour'].values\n",
    "minutes=df['minute'].values\n",
    "seconds=df['second'].values\n",
    "microseconds=df['microsecond'].values\n",
    "seconds_in_day=hours*3600+minutes*60+seconds+microseconds/1e6\n",
    "print('seconds in day min and max:')\n",
    "print(seconds_in_day.max(), seconds_in_day.min())\n",
    "doys=np.zeros((len(df),))\n",
    "for i in range(len(df)):\n",
    "    #date is a string, so I first convert it to datetime:\n",
    "    date_=datetime.datetime(year=years[i], \n",
    "                            month=months[i], \n",
    "                            day=days[i],\n",
    "                            hour=hours[i],\n",
    "                            minute=minutes[i],\n",
    "                            second=seconds[i],\n",
    "                            microsecond=microseconds[i])\n",
    "    doys[i]=date_.timetuple().tm_yday\n",
    "print('day of the year min and max:')\n",
    "print(doys.max(), doys.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['day',\n",
       " 'month',\n",
       " 'year',\n",
       " 'hour',\n",
       " 'minute',\n",
       " 'second',\n",
       " 'microsecond',\n",
       " 'alt [km]',\n",
       " 'lat [deg]',\n",
       " 'lon [deg]',\n",
       " 'f107A',\n",
       " 'f107',\n",
       " 'ap',\n",
       " 'wind zonal [m/s]',\n",
       " 'wind meridional [m/s]',\n",
       " 'density [kg/m^3]']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I extract the altitude:\n",
    "alt=df['alt [km]'].values\n",
    "#I now extract the longitude and latitude, and convert them to radians:\n",
    "lon=np.deg2rad(df['lon [deg]'].values)\n",
    "lat=np.deg2rad(df['lat [deg]'].values)\n",
    "#now the space weather indices:\n",
    "f107=df['f107'].values\n",
    "f107a=df['f107A'].values\n",
    "ap=df['ap'].values\n",
    "#let's extract the target density as well:\n",
    "target_density=df['density [kg/m^3]'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function normalizes the data to the range [-1,1]\n",
    "def normalize_min_max(data,min_val,max_val):\n",
    "    normalized_data = (2 * (data - min_val) / (max_val - min_val)) - 1\n",
    "    return normalized_data\n",
    "def unnormalize_min_max(data,min_val,max_val):\n",
    "    unnormalized_data = 1/2 * (data + 1) * (max_val - min_val) + min_val\n",
    "    return unnormalized_data\n",
    "#verify: unnormalize_min_max(normalize_min_max(alt,alt.min(),alt.max()),alt.min(),alt.max())==alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_normalized={}\n",
    "data_normalized['sin_lon'] = np.sin(lon)\n",
    "data_normalized['cos_lon'] = np.cos(lon)\n",
    "data_normalized['sin_lat'] = np.sin(lat)\n",
    "data_normalized['sin_sec_in_day'] = np.sin(2*np.pi*seconds_in_day/86400.)\n",
    "data_normalized['cos_sec_in_day'] = np.cos(2*np.pi*seconds_in_day/86400.)\n",
    "data_normalized['sin_doy'] = np.sin(2*np.pi*doys/365.25)\n",
    "data_normalized['cos_doy'] = np.cos(2*np.pi*doys/365.25)\n",
    "data_normalized['alt_n'] = normalize_min_max(alt, 150., 650.)\n",
    "data_normalized['f107_n'] = normalize_min_max(f107, 60., 290.)\n",
    "data_normalized['f107a_n'] = normalize_min_max(f107a, 50., 190.)\n",
    "data_normalized['ap_n'] = normalize_min_max(ap, 0., 140.)\n",
    "#I add the non-normalized density & altitude columns (useful to extract during training):\n",
    "data_normalized['altitude'] = alt  \n",
    "data_normalized['density'] = target_density\n",
    "df_normalized=pd.DataFrame(data_normalized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sin_lon</th>\n",
       "      <th>cos_lon</th>\n",
       "      <th>sin_lat</th>\n",
       "      <th>sin_sec_in_day</th>\n",
       "      <th>cos_sec_in_day</th>\n",
       "      <th>sin_doy</th>\n",
       "      <th>cos_doy</th>\n",
       "      <th>alt_n</th>\n",
       "      <th>f107_n</th>\n",
       "      <th>f107a_n</th>\n",
       "      <th>ap_n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>999800.000000</td>\n",
       "      <td>999800.000000</td>\n",
       "      <td>999800.000000</td>\n",
       "      <td>999800.000000</td>\n",
       "      <td>999800.000000</td>\n",
       "      <td>999800.000000</td>\n",
       "      <td>999800.000000</td>\n",
       "      <td>999800.000000</td>\n",
       "      <td>999800.000000</td>\n",
       "      <td>999800.000000</td>\n",
       "      <td>999800.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.009967</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>-0.013318</td>\n",
       "      <td>-0.001473</td>\n",
       "      <td>-0.008017</td>\n",
       "      <td>0.001431</td>\n",
       "      <td>-0.229933</td>\n",
       "      <td>-0.681896</td>\n",
       "      <td>-0.332459</td>\n",
       "      <td>-0.888046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.703531</td>\n",
       "      <td>0.710595</td>\n",
       "      <td>0.583207</td>\n",
       "      <td>0.709771</td>\n",
       "      <td>0.704306</td>\n",
       "      <td>0.705969</td>\n",
       "      <td>0.708197</td>\n",
       "      <td>0.543268</td>\n",
       "      <td>0.259316</td>\n",
       "      <td>0.380827</td>\n",
       "      <td>0.113224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.999874</td>\n",
       "      <td>-0.999497</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.999999</td>\n",
       "      <td>-0.999979</td>\n",
       "      <td>-0.966043</td>\n",
       "      <td>-0.965217</td>\n",
       "      <td>-0.755714</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.690079</td>\n",
       "      <td>-0.701475</td>\n",
       "      <td>-0.515152</td>\n",
       "      <td>-0.727022</td>\n",
       "      <td>-0.700686</td>\n",
       "      <td>-0.714292</td>\n",
       "      <td>-0.707487</td>\n",
       "      <td>-0.704495</td>\n",
       "      <td>-0.896522</td>\n",
       "      <td>-0.684286</td>\n",
       "      <td>-0.957143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015858</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>-0.014907</td>\n",
       "      <td>-0.018921</td>\n",
       "      <td>-0.006451</td>\n",
       "      <td>-0.011826</td>\n",
       "      <td>-0.335058</td>\n",
       "      <td>-0.782609</td>\n",
       "      <td>-0.501429</td>\n",
       "      <td>-0.928571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.712694</td>\n",
       "      <td>0.723734</td>\n",
       "      <td>0.515152</td>\n",
       "      <td>0.694340</td>\n",
       "      <td>0.707038</td>\n",
       "      <td>0.694452</td>\n",
       "      <td>0.715044</td>\n",
       "      <td>0.186767</td>\n",
       "      <td>-0.526087</td>\n",
       "      <td>-0.008571</td>\n",
       "      <td>-0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.999874</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.923829</td>\n",
       "      <td>0.756522</td>\n",
       "      <td>0.587143</td>\n",
       "      <td>0.542857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             sin_lon        cos_lon        sin_lat  sin_sec_in_day  \\\n",
       "count  999800.000000  999800.000000  999800.000000   999800.000000   \n",
       "mean        0.000168       0.009967       0.000028       -0.013318   \n",
       "std         0.703531       0.710595       0.583207        0.709771   \n",
       "min        -0.999874      -0.999497      -1.000000       -1.000000   \n",
       "25%        -0.690079      -0.701475      -0.515152       -0.727022   \n",
       "50%         0.000000       0.015858       0.010101       -0.014907   \n",
       "75%         0.712694       0.723734       0.515152        0.694340   \n",
       "max         0.999874       1.000000       1.000000        1.000000   \n",
       "\n",
       "       cos_sec_in_day        sin_doy        cos_doy          alt_n  \\\n",
       "count   999800.000000  999800.000000  999800.000000  999800.000000   \n",
       "mean        -0.001473      -0.008017       0.001431      -0.229933   \n",
       "std          0.704306       0.705969       0.708197       0.543268   \n",
       "min         -1.000000      -0.999999      -0.999979      -0.966043   \n",
       "25%         -0.700686      -0.714292      -0.707487      -0.704495   \n",
       "50%         -0.018921      -0.006451      -0.011826      -0.335058   \n",
       "75%          0.707038       0.694452       0.715044       0.186767   \n",
       "max          1.000000       0.999986       0.999991       0.923829   \n",
       "\n",
       "              f107_n        f107a_n           ap_n  \n",
       "count  999800.000000  999800.000000  999800.000000  \n",
       "mean       -0.681896      -0.332459      -0.888046  \n",
       "std         0.259316       0.380827       0.113224  \n",
       "min        -0.965217      -0.755714      -1.000000  \n",
       "25%        -0.896522      -0.684286      -0.957143  \n",
       "50%        -0.782609      -0.501429      -0.928571  \n",
       "75%        -0.526087      -0.008571      -0.857143  \n",
       "max         0.756522       0.587143       0.542857  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description_normalized=df_normalized.describe()\n",
    "description_normalized.iloc[:,:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum and minimum datapoints of the dataset: 1.0, -1.0\n",
      "maximum and minimum of target density: 1.720909357141654e-09, 2.162184111598853e-15\n"
     ]
    }
   ],
   "source": [
    "#cross check that the max is <=1 and the min is >=-1\n",
    "print(f\"maximum and minimum datapoints of the dataset: {description_normalized.iloc[:,:-2].loc['max'].max()}, {description_normalized.iloc[:,:-2].loc['min'].min()}\")\n",
    "print(f\"maximum and minimum of target density: {description_normalized.iloc[:,-1].loc['max'].max()}, {description_normalized.iloc[:,-1].loc['min'].min()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_data = torch.tensor(df_normalized.values,\n",
    "                          dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN hyperparameters\n",
    "device = torch.device('cpu')\n",
    "batch_size = 4096\n",
    "model_path = None #pass a path to a model in case you want to continue training\n",
    "lr = 0.00001\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader creation\n",
    "dataloader = torch.utils.data.DataLoader(torch_data, \n",
    "                                         batch_size=batch_size, \n",
    "                                         shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NN creation\n",
    "model = thermonets.ffnn(input_dim=len(df_normalized.columns)-2,\n",
    "                        hidden_layer_dims=[32, 32],\n",
    "                        output_dim=12,\n",
    "                        mid_activation=torch.nn.Tanh(),\n",
    "                        last_activation=torch.nn.Tanh()).to(device)\n",
    "\n",
    "if model_path is not None:\n",
    "    model.load_state_dict(torch.load(model_path,\n",
    "                                     map_location=device.type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NN training\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of model parameters: 1836\n"
     ]
    }
   ],
   "source": [
    "print(f'Total number of model parameters: {sum(p.numel() for p in model.parameters())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the global fit (see notebook: `rho_global_fit.ipynb`: this will be the baseline from which we ask the NN to learn corrections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/ga00693/Develop/thermonets/global_fits/global_fit_nrlmsise00_180.0-1000.0-4.txt','rb') as f:\n",
    "    best_global_fit=torch.from_numpy(pickle.load(f)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_pred, y_true):\n",
    "    \"\"\"\n",
    "    Compute the mean absolute percentage error (MAPE) between true and predicted values.\n",
    "    \n",
    "    Args:\n",
    "        y_true (`torch.tensor`): True values.\n",
    "        y_pred (`torch.tensor`): Predicted values.\n",
    "        \n",
    "    Returns:\n",
    "        `torch.tensor`: Mean absolute percentage error.\n",
    "    \"\"\"\n",
    "    return torch.mean(torch.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minibatch: 59/245, ratio: 1.8085699747, best loss till now: 0.1405232847, loss RMSE (log10) & MAPE -----  NN: 0.1488258839, 77.3640289; fit: 0.0822892594, 53.2157058\r"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "ratio_losses=[]\n",
    "rmse_per_minibatch_nn=[]\n",
    "mape_per_minibatch_nn=[]\n",
    "rmse_per_minibatch_fit=[]\n",
    "mape_per_minibatch_fit=[]\n",
    "for epoch in range(epochs):\n",
    "    model.train(True)  # Set model to training mode\n",
    "    total_rmse = 0.0\n",
    "    total_mape = 0.0\n",
    "    k=0\n",
    "    for batch_idx,el in enumerate(dataloader):\n",
    "        minibatch=el[:,:-2]\n",
    "        altitude=el[:,-2]\n",
    "        optimizer.zero_grad()  # Clear accumulated gradients    \n",
    "        minibatch=minibatch.to(device)\n",
    "        params = model(minibatch).to(device)\n",
    "\n",
    "        k+=1\n",
    "\n",
    "        minibatch=minibatch.to(device)\n",
    "        optimizer.zero_grad()  # Clear accumulated gradients\n",
    "        delta_params = model(minibatch).to(device)\n",
    "        #now I construct the inputs for the compute_approximated_density function as corrections from the global fit:\n",
    "        params = best_global_fit*(1+delta_params)\n",
    "        rho_nn=thermonets.rho_approximation(h=altitude,\n",
    "                                                params=params,\n",
    "                                                backend='torch')\n",
    "        rho_fit=torch.from_numpy(thermonets.rho_approximation(h=altitude.numpy(),\n",
    "                                                                params=best_global_fit.numpy()))\n",
    "        rho_target=el[:,-1].to(device)\n",
    "\n",
    "        loss = criterion(torch.log10(rho_nn), torch.log10(rho_target))\n",
    "        loss.backward()\n",
    "        #I also compute the global fit loss:\n",
    "        loss_fit =  torch.nn.MSELoss()(torch.log10(rho_fit).squeeze(), torch.log10(rho_target).squeeze())\n",
    "        #I update the weights:\n",
    "        optimizer.step()\n",
    "        #let's store the losses for the NN:\n",
    "        rmse_per_minibatch_nn.append(loss.item())\n",
    "        mape_per_minibatch_nn.append(mean_absolute_percentage_error(rho_nn, rho_target).item())\n",
    "        total_rmse+=rmse_per_minibatch_nn[-1]\n",
    "        total_mape+=mape_per_minibatch_nn[-1]\n",
    "        #now the same but for the global fit:\n",
    "        rmse_per_minibatch_fit.append(loss_fit.item())\n",
    "        mape_per_minibatch_fit.append(mean_absolute_percentage_error(rho_fit, rho_target).item())\n",
    "\n",
    "        #ratio of the loss between the NN and the fit (the lower, the more the NN is doing better than a global fit)\n",
    "        ratio_losses.append(loss.item()/loss_fit.item())\n",
    "        #I only save the best model:\n",
    "        if k>1:\n",
    "            if rmse_per_minibatch_nn[-1]<min(rmse_per_minibatch_nn[:-1]):    \n",
    "                #updating torch best model:\n",
    "                torch.save(model.state_dict(), f'best_model.pth')\n",
    "                best_loss=loss.item()\n",
    "                #print(f'Saving model - current best loss: {best_loss}\\n')\n",
    "        else:\n",
    "            best_loss=loss.item()\n",
    "        #I print every 10 minibatches:\n",
    "        if k%10:    \n",
    "            print(f'minibatch: {k}/{len(dataloader)}, ratio: {ratio_losses[-1]:.10f}, best loss till now: {best_loss:.10f}, loss RMSE (log10) & MAPE -----  NN: {loss.item():.10f}, {mape_per_minibatch_nn[-1]:.7f}; fit: {loss_fit.item():.10f}, {mape_per_minibatch_fit[-1]:.7f}', end='\\r')\n",
    "    #I also print at the end of the epoch\n",
    "    print(f'End of epoch {epoch + 1}/{epochs}, average RMSE (log10) loss: {total_rmse / len(dataloader)}, average MAPE: {total_mape / len(dataloader)}, ')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thermonets",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
