{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feed-forward training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import thermonets as tn\n",
    "import torch\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of database is: (999700, 14)\n"
     ]
    }
   ],
   "source": [
    "#Loads the data generated via `/scripts/generate_nrlmsise00_db.py` and print the columns\n",
    "#note that columns can be (len 16):\n",
    "#'day', 'month', 'year', 'hour', 'minute', 'second', 'microsecond', 'alt [km]', 'lat [deg]', 'lon [deg]', 'f107A', 'f107', 'ap', 'wind zonal [m/s]', 'wind meridional [m/s]', 'density [kg/m^3]'\n",
    "#or (len 14):\n",
    "#'day', 'month', 'year', 'hour', 'minute', 'second', 'microsecond', 'alt [km]', 'lat [deg]', 'lon [deg]', 'f107A', 'f107', 'ap', 'density [kg/m^3]'\n",
    "db=np.loadtxt('../dbs/nrlmsise00_db.txt',delimiter=',',skiprows=1)\n",
    "print(f'Shape of database is: {db.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting features of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seconds in day min and max:\n",
      "20.64977 86392.51835\n",
      "day of the year min and max:\n",
      "1.0 365.0\n"
     ]
    }
   ],
   "source": [
    "# Renames some of the db content with readable names\n",
    "days=db[:,0]\n",
    "months=db[:,1]\n",
    "years=db[:,2]\n",
    "hours=db[:,3]\n",
    "minutes=db[:,4]\n",
    "seconds=db[:,5]\n",
    "microseconds=db[:,6]\n",
    "alt=db[:,7]\n",
    "# Geodetic longitude and latitude are converted in radians:\n",
    "lat=np.deg2rad(db[:,8])\n",
    "lon=np.deg2rad(db[:,9])\n",
    "# Space weather indices:\n",
    "f107a=db[:,10]\n",
    "f107=db[:,11]\n",
    "ap=db[:,12]\n",
    "# Atmospheric density as well:\n",
    "target_density=db[:,-1]\n",
    "\n",
    "# We need to extract from the db also the doy (Day of Year) and the sid (seconds in day)\n",
    "seconds_in_day=hours*3600+minutes*60+seconds+microseconds/1e6\n",
    "print('seconds in day min and max:')\n",
    "print(seconds_in_day.min(), seconds_in_day.max())\n",
    "doys=np.zeros(db.shape[0])\n",
    "for i in range(len(db)):\n",
    "    #date is a string, so I first convert it to datetime:\n",
    "    date_=datetime.datetime(year=int(years[i]), \n",
    "                            month=int(months[i]), \n",
    "                            day=int(days[i]),\n",
    "                            hour=int(hours[i]),\n",
    "                            minute=int(minutes[i]),\n",
    "                            second=int(seconds[i]),\n",
    "                            microsecond=int(microseconds[i]))\n",
    "    doys[i]=date_.timetuple().tm_yday\n",
    "print('day of the year min and max:')\n",
    "print(doys.min(), doys.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum and minimum of all the normalized data: 0.9761904761904763, -1.0\n",
      "maximum and minimum of target density: 7.20569529348575e-10, 1.9693989513886182e-16\n"
     ]
    }
   ],
   "source": [
    "db_processed=np.zeros((db.shape[0],13))\n",
    "db_processed[:,0]=np.sin(lon)\n",
    "db_processed[:,1]=np.cos(lon)\n",
    "db_processed[:,2]=np.sin(lat)\n",
    "db_processed[:,3]=np.sin(2*np.pi*seconds_in_day/86400.)\n",
    "db_processed[:,4]=np.cos(2*np.pi*seconds_in_day/86400.)\n",
    "db_processed[:,5]=np.sin(2*np.pi*doys/365.25)\n",
    "db_processed[:,6]=np.cos(2*np.pi*doys/365.25)\n",
    "db_processed[:,7]=tn.normalize_min_max(f107, 60., 266.)\n",
    "db_processed[:,8]=tn.normalize_min_max(f107a, 60., 266.)\n",
    "db_processed[:,9]=tn.normalize_min_max(ap, 0., 110.)\n",
    "db_processed[:,10]=tn.normalize_min_max(alt, 170., 1010.)\n",
    "\n",
    "#Add the non-normalized density & altitude columns (useful to extract during training):\n",
    "db_processed[:,11]= alt\n",
    "db_processed[:,12]= target_density\n",
    "\n",
    "# Cross check that the max is <=1 and the min is >=-1\n",
    "print(f\"maximum and minimum of all the normalized data: {db_processed[:,7:11].max()}, {db_processed[:,7:11].min()}\")\n",
    "print(f\"maximum and minimum of target density: {target_density.max()}, {target_density.min()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_data = torch.tensor(db_processed, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN hyperparameters\n",
    "device = torch.device('cpu')\n",
    "minibatch_size = 4096\n",
    "model_path = None #pass a path to a model in case you want to continue training from a file\n",
    "lr = 0.001\n",
    "epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NN creation\n",
    "model = tn.ffnn(input_dim=db_processed.shape[1]-3,\n",
    "                        hidden_layer_dims=[32, 32],\n",
    "                        output_dim=12,\n",
    "                        mid_activation=torch.nn.Tanh(),\n",
    "                        last_activation=torch.nn.Tanh()).to(device)\n",
    "\n",
    "if model_path is not None:\n",
    "    model.load_state_dict(torch.load(model_path,\n",
    "                                     map_location=device.type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we set the optimizer\n",
    "lr = 1e-3\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor = 0.8, patience = 5000, min_lr = 1e-5, verbose=False)\n",
    "criterion = tn.MAPE()\n",
    "#criterion = tn.MSE_LOG10()\n",
    "\n",
    "# And the dataloader\n",
    "dataloader = torch.utils.data.DataLoader(torch_data, \n",
    "                                         batch_size=minibatch_size, \n",
    "                                         shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of model parameters: 1804\n"
     ]
    }
   ],
   "source": [
    "print(f'Total number of model parameters: {sum(p.numel() for p in model.parameters())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the global fit (see notebook: `rho_global_fit.ipynb`: this will be the baseline from which we ask the NN to learn corrections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../global_fits/global_fit_nrlmsise00_180.0-1000.0-4.txt','rb') as f:\n",
    "    best_global_fit=torch.from_numpy(pickle.load(f)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000, lr: 1.0e-03, average MSE (log10) loss: 29.77154151760802, average MAPE: 29.77154151760802                                                                                                                                                             \n",
      "Epoch 2/1000, lr: 1.0e-03, average MSE (log10) loss: 15.341805800613091, average MAPE: 15.341805800613091                                                                                                                                                             \n",
      "Epoch 3/1000, lr: 1.0e-03, average MSE (log10) loss: 11.904366633356833, average MAPE: 11.904366633356833                                                                                                                                                             \n",
      "Epoch 4/1000, lr: 1.0e-03, average MSE (log10) loss: 10.527999877929688, average MAPE: 10.527999877929688                                                                                                                                                             \n",
      "Epoch 5/1000, lr: 1.0e-03, average MSE (log10) loss: 9.790375312493772, average MAPE: 9.790375312493772                                                                                                                                                             \n",
      "Epoch 6/1000, lr: 1.0e-03, average MSE (log10) loss: 9.258352135638802, average MAPE: 9.258352135638802                                                                                                                                                             \n",
      "Epoch 7/1000, lr: 1.0e-03, average MSE (log10) loss: 8.863660582717584, average MAPE: 8.863660582717584                                                                                                                                                             \n",
      "Epoch 8/1000, lr: 1.0e-03, average MSE (log10) loss: 8.471942697252546, average MAPE: 8.471942697252546                                                                                                                                                             \n",
      "Epoch 9/1000, lr: 1.0e-03, average MSE (log10) loss: 8.194259960797368, average MAPE: 8.194259960797368                                                                                                                                                             \n",
      "Epoch 10/1000, lr: 1.0e-03, average MSE (log10) loss: 7.922101966702209, average MAPE: 7.922101966702209                                                                                                                                                             \n",
      "Epoch 11/1000, lr: 1.0e-03, average MSE (log10) loss: 7.68867532769028, average MAPE: 7.68867532769028                                                                                                                                                             \n",
      "Epoch 12/1000, lr: 1.0e-03, average MSE (log10) loss: 7.5007350396136845, average MAPE: 7.5007350396136845                                                                                                                                                             \n",
      "Epoch 13/1000, lr: 1.0e-03, average MSE (log10) loss: 7.379375566755022, average MAPE: 7.379375566755022                                                                                                                                                             \n",
      "Epoch 14/1000, lr: 1.0e-03, average MSE (log10) loss: 7.245504108740359, average MAPE: 7.245504108740359                                                                                                                                                             \n",
      "Epoch 15/1000, lr: 1.0e-03, average MSE (log10) loss: 7.139878588306661, average MAPE: 7.139878588306661                                                                                                                                                             \n",
      "Epoch 16/1000, lr: 1.0e-03, average MSE (log10) loss: 7.046220748278559, average MAPE: 7.046220748278559                                                                                                                                                             \n",
      "Epoch 17/1000, lr: 1.0e-03, average MSE (log10) loss: 6.981050485494185, average MAPE: 6.981050485494185                                                                                                                                                             \n",
      "Epoch 18/1000, lr: 1.0e-03, average MSE (log10) loss: 6.920333058493478, average MAPE: 6.920333058493478                                                                                                                                                             \n",
      "Epoch 19/1000, lr: 1.0e-03, average MSE (log10) loss: 6.865732535537409, average MAPE: 6.865732535537409                                                                                                                                                             \n",
      "Epoch 20/1000, lr: 1.0e-03, average MSE (log10) loss: 6.813924964593381, average MAPE: 6.813924964593381                                                                                                                                                             \n",
      "Epoch 21/1000, lr: 1.0e-03, average MSE (log10) loss: 6.736989706389758, average MAPE: 6.736989706389758                                                                                                                                                             \n",
      "Epoch 22/1000, lr: 1.0e-03, average MSE (log10) loss: 6.705861204497668, average MAPE: 6.705861204497668                                                                                                                                                             \n",
      "Epoch 23/1000, lr: 1.0e-03, average MSE (log10) loss: 6.658628127039695, average MAPE: 6.658628127039695                                                                                                                                                             \n",
      "Epoch 24/1000, lr: 1.0e-03, average MSE (log10) loss: 6.630081869631398, average MAPE: 6.630081869631398                                                                                                                                                             \n",
      "Epoch 25/1000, lr: 1.0e-03, average MSE (log10) loss: 6.576605152597232, average MAPE: 6.576605152597232                                                                                                                                                             \n",
      "Epoch 26/1000, lr: 1.0e-03, average MSE (log10) loss: 6.553327060232357, average MAPE: 6.553327060232357                                                                                                                                                             \n",
      "Epoch 27/1000, lr: 1.0e-03, average MSE (log10) loss: 6.51486613993742, average MAPE: 6.51486613993742                                                                                                                                                             \n",
      "Epoch 28/1000, lr: 1.0e-03, average MSE (log10) loss: 6.471725329574274, average MAPE: 6.471725329574274                                                                                                                                                             \n",
      "Epoch 29/1000, lr: 1.0e-03, average MSE (log10) loss: 6.453799627265152, average MAPE: 6.453799627265152                                                                                                                                                             \n",
      "Epoch 30/1000, lr: 1.0e-03, average MSE (log10) loss: 6.401579010243318, average MAPE: 6.401579010243318                                                                                                                                                             \n",
      "Epoch 31/1000, lr: 1.0e-03, average MSE (log10) loss: 6.402046145225058, average MAPE: 6.402046145225058                                                                                                                                                             \n",
      "Epoch 32/1000, lr: 1.0e-03, average MSE (log10) loss: 6.344776155510727, average MAPE: 6.344776155510727                                                                                                                                                             \n",
      "Epoch 33/1000, lr: 1.0e-03, average MSE (log10) loss: 6.3235811759014515, average MAPE: 6.3235811759014515                                                                                                                                                             \n",
      "Epoch 34/1000, lr: 1.0e-03, average MSE (log10) loss: 6.31138249611368, average MAPE: 6.31138249611368                                                                                                                                                             \n",
      "Epoch 35/1000, lr: 1.0e-03, average MSE (log10) loss: 6.288790235714036, average MAPE: 6.288790235714036                                                                                                                                                             \n",
      "Epoch 36/1000, lr: 1.0e-03, average MSE (log10) loss: 6.253457686365867, average MAPE: 6.253457686365867                                                                                                                                                             \n",
      "Epoch 37/1000, lr: 1.0e-03, average MSE (log10) loss: 6.227855660964032, average MAPE: 6.227855660964032                                                                                                                                                             \n",
      "Epoch 38/1000, lr: 1.0e-03, average MSE (log10) loss: 6.177418683499706, average MAPE: 6.177418683499706                                                                                                                                                             \n",
      "Epoch 39/1000, lr: 1.0e-03, average MSE (log10) loss: 6.171046011788505, average MAPE: 6.171046011788505                                                                                                                                                             \n",
      "Epoch 40/1000, lr: 1.0e-03, average MSE (log10) loss: 6.143493465501435, average MAPE: 6.143493465501435                                                                                                                                                             \n",
      "Epoch 41/1000, lr: 1.0e-03, average MSE (log10) loss: 6.103916802698252, average MAPE: 6.103916802698252                                                                                                                                                             \n",
      "Epoch 42/1000, lr: 1.0e-03, average MSE (log10) loss: 6.096428005062804, average MAPE: 6.096428005062804                                                                                                                                                             \n",
      "Epoch 43/1000, lr: 1.0e-03, average MSE (log10) loss: 6.064407064476792, average MAPE: 6.064407064476792                                                                                                                                                             \n",
      "Epoch 44/1000, lr: 1.0e-03, average MSE (log10) loss: 6.064722049479582, average MAPE: 6.064722049479582                                                                                                                                                             \n",
      "Epoch 45/1000, lr: 1.0e-03, average MSE (log10) loss: 6.035354629828006, average MAPE: 6.035354629828006                                                                                                                                                             \n",
      "Epoch 46/1000, lr: 1.0e-03, average MSE (log10) loss: 6.0055924707529496, average MAPE: 6.0055924707529496                                                                                                                                                             \n",
      "Epoch 47/1000, lr: 1.0e-03, average MSE (log10) loss: 5.977887683012048, average MAPE: 5.977887683012048                                                                                                                                                             \n",
      "Epoch 48/1000, lr: 1.0e-03, average MSE (log10) loss: 5.98768666715038, average MAPE: 5.98768666715038                                                                                                                                                             \n",
      "Epoch 49/1000, lr: 1.0e-03, average MSE (log10) loss: 5.937496206711749, average MAPE: 5.937496206711749                                                                                                                                                             \n",
      "Epoch 50/1000, lr: 1.0e-03, average MSE (log10) loss: 5.916708325366584, average MAPE: 5.916708325366584                                                                                                                                                             \n",
      "Epoch 51/1000, lr: 1.0e-03, average MSE (log10) loss: 5.8936082567487444, average MAPE: 5.8936082567487444                                                                                                                                                             \n",
      "Epoch 52/1000, lr: 1.0e-03, average MSE (log10) loss: 5.8865250237134035, average MAPE: 5.8865250237134035                                                                                                                                                             \n",
      "Epoch 53/1000, lr: 1.0e-03, average MSE (log10) loss: 5.872730089693653, average MAPE: 5.872730089693653                                                                                                                                                             \n",
      "Epoch 54/1000, lr: 1.0e-03, average MSE (log10) loss: 5.848120416913714, average MAPE: 5.848120416913714                                                                                                                                                             \n",
      "Epoch 55/1000, lr: 1.0e-03, average MSE (log10) loss: 5.806525849322884, average MAPE: 5.806525849322884                                                                                                                                                             \n",
      "Epoch 56/1000, lr: 1.0e-03, average MSE (log10) loss: 5.815926711413325, average MAPE: 5.815926711413325                                                                                                                                                             \n",
      "Epoch 57/1000, lr: 1.0e-03, average MSE (log10) loss: 5.756973507939553, average MAPE: 5.756973507939553                                                                                                                                                             \n",
      "Epoch 58/1000, lr: 1.0e-03, average MSE (log10) loss: 5.731878282585923, average MAPE: 5.731878282585923                                                                                                                                                             \n",
      "Epoch 59/1000, lr: 1.0e-03, average MSE (log10) loss: 5.741432244437082, average MAPE: 5.741432244437082                                                                                                                                                             \n",
      "Epoch 60/1000, lr: 1.0e-03, average MSE (log10) loss: 5.721234858765894, average MAPE: 5.721234858765894                                                                                                                                                             \n",
      "Epoch 61/1000, lr: 1.0e-03, average MSE (log10) loss: 5.6714929035731725, average MAPE: 5.6714929035731725                                                                                                                                                             \n",
      "Epoch 62/1000, lr: 1.0e-03, average MSE (log10) loss: 5.689575586513597, average MAPE: 5.689575586513597                                                                                                                                                             \n",
      "Epoch 63/1000, lr: 1.0e-03, average MSE (log10) loss: 5.646617560483971, average MAPE: 5.646617560483971                                                                                                                                                             \n",
      "Epoch 64/1000, lr: 1.0e-03, average MSE (log10) loss: 5.638934713480424, average MAPE: 5.638934713480424                                                                                                                                                             \n",
      "Epoch 65/1000, lr: 1.0e-03, average MSE (log10) loss: 5.606152635691117, average MAPE: 5.606152635691117                                                                                                                                                             \n",
      "Epoch 66/1000, lr: 1.0e-03, average MSE (log10) loss: 5.600211571673958, average MAPE: 5.600211571673958                                                                                                                                                             \n",
      "Epoch 67/1000, lr: 1.0e-03, average MSE (log10) loss: 5.573519685317059, average MAPE: 5.573519685317059                                                                                                                                                             \n",
      "Epoch 68/1000, lr: 1.0e-03, average MSE (log10) loss: 5.569522135598319, average MAPE: 5.569522135598319                                                                                                                                                             \n",
      "Epoch 69/1000, lr: 1.0e-03, average MSE (log10) loss: 5.547499522384332, average MAPE: 5.547499522384332                                                                                                                                                             \n",
      "Epoch 70/1000, lr: 1.0e-03, average MSE (log10) loss: 5.504326551787707, average MAPE: 5.504326551787707                                                                                                                                                             \n",
      "Epoch 71/1000, lr: 1.0e-03, average MSE (log10) loss: 5.502644227475536, average MAPE: 5.502644227475536                                                                                                                                                             \n",
      "Epoch 72/1000, lr: 1.0e-03, average MSE (log10) loss: 5.4958429219771405, average MAPE: 5.4958429219771405                                                                                                                                                             \n",
      "Epoch 73/1000, lr: 1.0e-03, average MSE (log10) loss: 5.464215457682707, average MAPE: 5.464215457682707                                                                                                                                                             \n",
      "Epoch 74/1000, lr: 1.0e-03, average MSE (log10) loss: 5.445929756943061, average MAPE: 5.445929756943061                                                                                                                                                             \n",
      "Epoch 75/1000, lr: 1.0e-03, average MSE (log10) loss: 5.438753460864631, average MAPE: 5.438753460864631                                                                                                                                                             \n",
      "Epoch 76/1000, lr: 1.0e-03, average MSE (log10) loss: 5.425413824587452, average MAPE: 5.425413824587452                                                                                                                                                             \n",
      "Epoch 77/1000, lr: 1.0e-03, average MSE (log10) loss: 5.399842369313142, average MAPE: 5.399842369313142                                                                                                                                                             \n",
      "Epoch 78/1000, lr: 1.0e-03, average MSE (log10) loss: 5.423281673509248, average MAPE: 5.423281673509248                                                                                                                                                             \n",
      "Epoch 79/1000, lr: 1.0e-03, average MSE (log10) loss: 5.377032104803591, average MAPE: 5.377032104803591                                                                                                                                                             \n",
      "Epoch 80/1000, lr: 1.0e-03, average MSE (log10) loss: 5.359326697369011, average MAPE: 5.359326697369011                                                                                                                                                             \n",
      "Epoch 81/1000, lr: 1.0e-03, average MSE (log10) loss: 5.352829257809386, average MAPE: 5.352829257809386                                                                                                                                                             \n",
      "Epoch 82/1000, lr: 1.0e-03, average MSE (log10) loss: 5.358846331615838, average MAPE: 5.358846331615838                                                                                                                                                             \n",
      "Epoch 83/1000, lr: 1.0e-03, average MSE (log10) loss: 5.317968966036426, average MAPE: 5.317968966036426                                                                                                                                                             \n",
      "Epoch 84/1000, lr: 1.0e-03, average MSE (log10) loss: 5.318282045636859, average MAPE: 5.318282045636859                                                                                                                                                             \n",
      "Epoch 85/1000, lr: 1.0e-03, average MSE (log10) loss: 5.294366349979323, average MAPE: 5.294366349979323                                                                                                                                                             \n",
      "Epoch 86/1000, lr: 1.0e-03, average MSE (log10) loss: 5.320114050106127, average MAPE: 5.320114050106127                                                                                                                                                             \n",
      "Epoch 87/1000, lr: 1.0e-03, average MSE (log10) loss: 5.24969880629559, average MAPE: 5.24969880629559                                                                                                                                                             \n",
      "Epoch 88/1000, lr: 1.0e-03, average MSE (log10) loss: 5.244569046643315, average MAPE: 5.244569046643315                                                                                                                                                             \n",
      "Epoch 89/1000, lr: 1.0e-03, average MSE (log10) loss: 5.2383513275457885, average MAPE: 5.2383513275457885                                                                                                                                                             \n",
      "Epoch 90/1000, lr: 1.0e-03, average MSE (log10) loss: 5.222692719284369, average MAPE: 5.222692719284369                                                                                                                                                             \n",
      "Epoch 91/1000, lr: 1.0e-03, average MSE (log10) loss: 5.210244532993862, average MAPE: 5.210244532993862                                                                                                                                                             \n",
      "Epoch 92/1000, lr: 1.0e-03, average MSE (log10) loss: 5.199192041280318, average MAPE: 5.199192041280318                                                                                                                                                             \n",
      "Epoch 93/1000, lr: 1.0e-03, average MSE (log10) loss: 5.157640270311005, average MAPE: 5.157640270311005                                                                                                                                                             \n",
      "Epoch 94/1000, lr: 1.0e-03, average MSE (log10) loss: 5.188427232236278, average MAPE: 5.188427232236278                                                                                                                                                             \n",
      "Epoch 95/1000, lr: 1.0e-03, average MSE (log10) loss: 5.168297415363545, average MAPE: 5.168297415363545                                                                                                                                                             \n",
      "Epoch 96/1000, lr: 1.0e-03, average MSE (log10) loss: 5.124289874641263, average MAPE: 5.124289874641263                                                                                                                                                             \n",
      "Epoch 97/1000, lr: 1.0e-03, average MSE (log10) loss: 5.174061814133002, average MAPE: 5.174061814133002                                                                                                                                                             \n",
      "Epoch 98/1000, lr: 1.0e-03, average MSE (log10) loss: 5.120665032523019, average MAPE: 5.120665032523019                                                                                                                                                             \n",
      "Epoch 99/1000, lr: 1.0e-03, average MSE (log10) loss: 5.090317938279132, average MAPE: 5.090317938279132                                                                                                                                                             \n",
      "Epoch 100/1000, lr: 1.0e-03, average MSE (log10) loss: 5.105730346757539, average MAPE: 5.105730346757539                                                                                                                                                             \n",
      "Epoch 101/1000, lr: 1.0e-03, average MSE (log10) loss: 5.071345630957156, average MAPE: 5.071345630957156                                                                                                                                                             \n",
      "Epoch 102/1000, lr: 1.0e-03, average MSE (log10) loss: 5.061954181048335, average MAPE: 5.061954181048335                                                                                                                                                             \n",
      "Epoch 103/1000, lr: 1.0e-03, average MSE (log10) loss: 5.051685802304015, average MAPE: 5.051685802304015                                                                                                                                                             \n",
      "Epoch 104/1000, lr: 1.0e-03, average MSE (log10) loss: 5.039346336831852, average MAPE: 5.039346336831852                                                                                                                                                             \n",
      "Epoch 105/1000, lr: 1.0e-03, average MSE (log10) loss: 5.0125615995757435, average MAPE: 5.0125615995757435                                                                                                                                                             \n",
      "Epoch 106/1000, lr: 1.0e-03, average MSE (log10) loss: 5.01465127516766, average MAPE: 5.01465127516766                                                                                                                                                             \n",
      "Epoch 107/1000, lr: 1.0e-03, average MSE (log10) loss: 5.0007348313623545, average MAPE: 5.0007348313623545                                                                                                                                                             \n",
      "Epoch 108/1000, lr: 1.0e-03, average MSE (log10) loss: 4.992701402002451, average MAPE: 4.992701402002451                                                                                                                                                             \n",
      "Epoch 109/1000, lr: 1.0e-03, average MSE (log10) loss: 4.966336367081623, average MAPE: 4.966336367081623                                                                                                                                                             \n",
      "Epoch 110/1000, lr: 1.0e-03, average MSE (log10) loss: 4.964378716994305, average MAPE: 4.964378716994305                                                                                                                                                             \n",
      "Epoch 111/1000, lr: 1.0e-03, average MSE (log10) loss: 4.983099859588, average MAPE: 4.983099859588                                                                                                                                                             \n",
      "Epoch 112/1000, lr: 1.0e-03, average MSE (log10) loss: 4.901467562694939, average MAPE: 4.901467562694939                                                                                                                                                             \n",
      "Epoch 113/1000, lr: 1.0e-03, average MSE (log10) loss: 4.9116872962640254, average MAPE: 4.9116872962640254                                                                                                                                                             \n",
      "Epoch 114/1000, lr: 1.0e-03, average MSE (log10) loss: 4.90915105002267, average MAPE: 4.90915105002267                                                                                                                                                             \n",
      "Epoch 115/1000, lr: 1.0e-03, average MSE (log10) loss: 4.8729543316121005, average MAPE: 4.8729543316121005                                                                                                                                                             \n",
      "Epoch 116/1000, lr: 8.0e-04, average MSE (log10) loss: 4.863551334458954, average MAPE: 4.863551334458954                                                                                                                                                             \n",
      "Epoch 117/1000, lr: 8.0e-04, average MSE (log10) loss: 4.81476206098284, average MAPE: 4.81476206098284                                                                                                                                                             \n",
      "Epoch 118/1000, lr: 8.0e-04, average MSE (log10) loss: 4.803827548513607, average MAPE: 4.803827548513607                                                                                                                                                             \n",
      "Epoch 119/1000, lr: 8.0e-04, average MSE (log10) loss: 4.7973906186162205, average MAPE: 4.7973906186162205                                                                                                                                                             \n",
      "Epoch 120/1000, lr: 8.0e-04, average MSE (log10) loss: 4.8021765358594, average MAPE: 4.8021765358594                                                                                                                                                             \n",
      "Epoch 121/1000, lr: 8.0e-04, average MSE (log10) loss: 4.7795207724279285, average MAPE: 4.7795207724279285                                                                                                                                                             \n",
      "Epoch 122/1000, lr: 8.0e-04, average MSE (log10) loss: 4.765927604753144, average MAPE: 4.765927604753144                                                                                                                                                             \n",
      "Epoch 123/1000, lr: 8.0e-04, average MSE (log10) loss: 4.76589189451568, average MAPE: 4.76589189451568                                                                                                                                                             \n",
      "Epoch 124/1000, lr: 8.0e-04, average MSE (log10) loss: 4.750635320313123, average MAPE: 4.750635320313123                                                                                                                                                             \n",
      "Epoch 125/1000, lr: 8.0e-04, average MSE (log10) loss: 4.776448964099495, average MAPE: 4.776448964099495                                                                                                                                                             \n",
      "Epoch 126/1000, lr: 8.0e-04, average MSE (log10) loss: 4.7220972275247375, average MAPE: 4.7220972275247375                                                                                                                                                             \n",
      "Epoch 127/1000, lr: 8.0e-04, average MSE (log10) loss: 4.718663054096456, average MAPE: 4.718663054096456                                                                                                                                                             \n",
      "Epoch 128/1000, lr: 8.0e-04, average MSE (log10) loss: 4.7078267778669085, average MAPE: 4.7078267778669085                                                                                                                                                             \n",
      "Epoch 129/1000, lr: 8.0e-04, average MSE (log10) loss: 4.674211834888069, average MAPE: 4.674211834888069                                                                                                                                                             \n",
      "Epoch 130/1000, lr: 8.0e-04, average MSE (log10) loss: 4.6693431893173525, average MAPE: 4.6693431893173525                                                                                                                                                             \n",
      "Epoch 131/1000, lr: 8.0e-04, average MSE (log10) loss: 4.6781656576662645, average MAPE: 4.6781656576662645                                                                                                                                                             \n",
      "Epoch 132/1000, lr: 8.0e-04, average MSE (log10) loss: 4.646552155942333, average MAPE: 4.646552155942333                                                                                                                                                             \n",
      "Epoch 133/1000, lr: 8.0e-04, average MSE (log10) loss: 4.631776484664606, average MAPE: 4.631776484664606                                                                                                                                                             \n",
      "Epoch 134/1000, lr: 8.0e-04, average MSE (log10) loss: 4.651348801048434, average MAPE: 4.651348801048434                                                                                                                                                             \n",
      "Epoch 135/1000, lr: 8.0e-04, average MSE (log10) loss: 4.671842425210135, average MAPE: 4.671842425210135                                                                                                                                                             \n",
      "Epoch 136/1000, lr: 8.0e-04, average MSE (log10) loss: 4.610357366289411, average MAPE: 4.610357366289411                                                                                                                                                             \n",
      "Epoch 137/1000, lr: 8.0e-04, average MSE (log10) loss: 4.611522612279775, average MAPE: 4.611522612279775                                                                                                                                                             \n",
      "Epoch 138/1000, lr: 8.0e-04, average MSE (log10) loss: 4.610040137232566, average MAPE: 4.610040137232566                                                                                                                                                             \n",
      "Epoch 139/1000, lr: 8.0e-04, average MSE (log10) loss: 4.589531024621458, average MAPE: 4.589531024621458                                                                                                                                                             \n",
      "Epoch 140/1000, lr: 8.0e-04, average MSE (log10) loss: 4.5866850152307626, average MAPE: 4.5866850152307626                                                                                                                                                             \n",
      "Epoch 141/1000, lr: 8.0e-04, average MSE (log10) loss: 4.58703023949448, average MAPE: 4.58703023949448                                                                                                                                                             \n",
      "Epoch 142/1000, lr: 8.0e-04, average MSE (log10) loss: 4.560086265875369, average MAPE: 4.560086265875369                                                                                                                                                             \n",
      "Epoch 143/1000, lr: 8.0e-04, average MSE (log10) loss: 4.5591894908827175, average MAPE: 4.5591894908827175                                                                                                                                                             \n",
      "Epoch 144/1000, lr: 8.0e-04, average MSE (log10) loss: 4.544541076738007, average MAPE: 4.544541076738007                                                                                                                                                             \n",
      "Epoch 145/1000, lr: 8.0e-04, average MSE (log10) loss: 4.557293284669214, average MAPE: 4.557293284669214                                                                                                                                                             \n",
      "Epoch 146/1000, lr: 8.0e-04, average MSE (log10) loss: 4.510466156200486, average MAPE: 4.510466156200486                                                                                                                                                             \n",
      "Epoch 147/1000, lr: 8.0e-04, average MSE (log10) loss: 4.560134192875453, average MAPE: 4.560134192875453                                                                                                                                                             \n",
      "Epoch 148/1000, lr: 8.0e-04, average MSE (log10) loss: 4.520716106648348, average MAPE: 4.520716106648348                                                                                                                                                             \n",
      "Epoch 149/1000, lr: 8.0e-04, average MSE (log10) loss: 4.500135900536362, average MAPE: 4.500135900536362                                                                                                                                                             \n",
      "Epoch 150/1000, lr: 8.0e-04, average MSE (log10) loss: 4.513159366529815, average MAPE: 4.513159366529815                                                                                                                                                             \n",
      "Epoch 151/1000, lr: 8.0e-04, average MSE (log10) loss: 4.491974873445472, average MAPE: 4.491974873445472                                                                                                                                                             \n",
      "Epoch 152/1000, lr: 8.0e-04, average MSE (log10) loss: 4.4969074716373365, average MAPE: 4.4969074716373365                                                                                                                                                             \n",
      "Epoch 153/1000, lr: 8.0e-04, average MSE (log10) loss: 4.475939536581234, average MAPE: 4.475939536581234                                                                                                                                                             \n",
      "Epoch 154/1000, lr: 8.0e-04, average MSE (log10) loss: 4.477603674908074, average MAPE: 4.477603674908074                                                                                                                                                             \n",
      "Epoch 155/1000, lr: 8.0e-04, average MSE (log10) loss: 4.451977307455881, average MAPE: 4.451977307455881                                                                                                                                                             \n",
      "Epoch 156/1000, lr: 8.0e-04, average MSE (log10) loss: 4.472665714731022, average MAPE: 4.472665714731022                                                                                                                                                             \n",
      "Epoch 157/1000, lr: 8.0e-04, average MSE (log10) loss: 4.457679715448497, average MAPE: 4.457679715448497                                                                                                                                                             \n",
      "Epoch 158/1000, lr: 8.0e-04, average MSE (log10) loss: 4.452610671763518, average MAPE: 4.452610671763518                                                                                                                                                             \n",
      "Epoch 159/1000, lr: 8.0e-04, average MSE (log10) loss: 4.461637411312181, average MAPE: 4.461637411312181                                                                                                                                                             \n",
      "Epoch 160/1000, lr: 8.0e-04, average MSE (log10) loss: 4.4431870771914115, average MAPE: 4.4431870771914115                                                                                                                                                             \n",
      "Epoch 161/1000, lr: 8.0e-04, average MSE (log10) loss: 4.421994802903156, average MAPE: 4.421994802903156                                                                                                                                                             \n",
      "Epoch 162/1000, lr: 8.0e-04, average MSE (log10) loss: 4.425737992111517, average MAPE: 4.425737992111517                                                                                                                                                             \n",
      "Epoch 163/1000, lr: 8.0e-04, average MSE (log10) loss: 4.4263373336013485, average MAPE: 4.4263373336013485                                                                                                                                                             \n",
      "Epoch 164/1000, lr: 8.0e-04, average MSE (log10) loss: 4.40707020273014, average MAPE: 4.40707020273014                                                                                                                                                             \n",
      "Epoch 165/1000, lr: 8.0e-04, average MSE (log10) loss: 4.410408882218964, average MAPE: 4.410408882218964                                                                                                                                                             \n",
      "Epoch 166/1000, lr: 8.0e-04, average MSE (log10) loss: 4.396173835287288, average MAPE: 4.396173835287288                                                                                                                                                             \n",
      "Epoch 167/1000, lr: 6.4e-04, average MSE (log10) loss: 4.387762460903246, average MAPE: 4.387762460903246                                                                                                                                                             \n",
      "Epoch 168/1000, lr: 6.4e-04, average MSE (log10) loss: 4.352135290418352, average MAPE: 4.352135290418352                                                                                                                                                             \n",
      "Epoch 169/1000, lr: 6.4e-04, average MSE (log10) loss: 4.362992159201174, average MAPE: 4.362992159201174                                                                                                                                                             \n",
      "Epoch 170/1000, lr: 6.4e-04, average MSE (log10) loss: 4.345700285386066, average MAPE: 4.345700285386066                                                                                                                                                             \n",
      "Epoch 171/1000, lr: 6.4e-04, average MSE (log10) loss: 4.374232004126724, average MAPE: 4.374232004126724                                                                                                                                                             \n",
      "Epoch 172/1000, lr: 6.4e-04, average MSE (log10) loss: 4.3544148133725535, average MAPE: 4.3544148133725535                                                                                                                                                             \n",
      "Epoch 173/1000, lr: 6.4e-04, average MSE (log10) loss: 4.335774927723165, average MAPE: 4.335774927723165                                                                                                                                                             \n",
      "Epoch 174/1000, lr: 6.4e-04, average MSE (log10) loss: 4.342891506272919, average MAPE: 4.342891506272919                                                                                                                                                             \n",
      "Epoch 175/1000, lr: 6.4e-04, average MSE (log10) loss: 4.350078495181337, average MAPE: 4.350078495181337                                                                                                                                                             \n",
      "Epoch 176/1000, lr: 6.4e-04, average MSE (log10) loss: 4.350558528121637, average MAPE: 4.350558528121637                                                                                                                                                             \n",
      "Epoch 177/1000, lr: 6.4e-04, average MSE (log10) loss: 4.344538538796561, average MAPE: 4.344538538796561                                                                                                                                                             \n",
      "Epoch 178/1000, lr: 6.4e-04, average MSE (log10) loss: 4.3217717073401625, average MAPE: 4.3217717073401625                                                                                                                                                             \n",
      "Epoch 179/1000, lr: 6.4e-04, average MSE (log10) loss: 4.329128461954545, average MAPE: 4.329128461954545                                                                                                                                                             \n",
      "Epoch 180/1000, lr: 6.4e-04, average MSE (log10) loss: 4.315321538886246, average MAPE: 4.315321538886246                                                                                                                                                             \n",
      "Epoch 181/1000, lr: 6.4e-04, average MSE (log10) loss: 4.31450182077836, average MAPE: 4.31450182077836                                                                                                                                                             \n",
      "Epoch 182/1000, lr: 6.4e-04, average MSE (log10) loss: 4.305454250257842, average MAPE: 4.305454250257842                                                                                                                                                             \n",
      "Epoch 183/1000, lr: 6.4e-04, average MSE (log10) loss: 4.310748305612681, average MAPE: 4.310748305612681                                                                                                                                                             \n",
      "Epoch 184/1000, lr: 6.4e-04, average MSE (log10) loss: 4.30555410677073, average MAPE: 4.30555410677073                                                                                                                                                             \n",
      "Epoch 185/1000, lr: 6.4e-04, average MSE (log10) loss: 4.302063500151342, average MAPE: 4.302063500151342                                                                                                                                                             \n",
      "Epoch 186/1000, lr: 6.4e-04, average MSE (log10) loss: 4.283919756753104, average MAPE: 4.283919756753104                                                                                                                                                             \n",
      "Epoch 187/1000, lr: 6.4e-04, average MSE (log10) loss: 4.297857185285919, average MAPE: 4.297857185285919                                                                                                                                                             \n",
      "Epoch 188/1000, lr: 6.4e-04, average MSE (log10) loss: 4.285273824419294, average MAPE: 4.285273824419294                                                                                                                                                             \n",
      "Epoch 189/1000, lr: 6.4e-04, average MSE (log10) loss: 4.282459547081772, average MAPE: 4.282459547081772                                                                                                                                                             \n",
      "Epoch 190/1000, lr: 6.4e-04, average MSE (log10) loss: 4.2759773273857276, average MAPE: 4.2759773273857276                                                                                                                                                             \n",
      "Epoch 191/1000, lr: 6.4e-04, average MSE (log10) loss: 4.2832723967883055, average MAPE: 4.2832723967883055                                                                                                                                                             \n",
      "Epoch 192/1000, lr: 6.4e-04, average MSE (log10) loss: 4.268127986363003, average MAPE: 4.268127986363003                                                                                                                                                             \n",
      "Epoch 193/1000, lr: 6.4e-04, average MSE (log10) loss: 4.260110946577423, average MAPE: 4.260110946577423                                                                                                                                                             \n",
      "Epoch 194/1000, lr: 6.4e-04, average MSE (log10) loss: 4.283190100533622, average MAPE: 4.283190100533622                                                                                                                                                             \n",
      "Epoch 195/1000, lr: 6.4e-04, average MSE (log10) loss: 4.25913776183615, average MAPE: 4.25913776183615                                                                                                                                                             \n",
      "Epoch 196/1000, lr: 6.4e-04, average MSE (log10) loss: 4.2537666671130125, average MAPE: 4.2537666671130125                                                                                                                                                             \n",
      "Epoch 197/1000, lr: 6.4e-04, average MSE (log10) loss: 4.264963449750628, average MAPE: 4.264963449750628                                                                                                                                                             \n",
      "Epoch 198/1000, lr: 6.4e-04, average MSE (log10) loss: 4.241189001044448, average MAPE: 4.241189001044448                                                                                                                                                             \n",
      "Epoch 199/1000, lr: 6.4e-04, average MSE (log10) loss: 4.2491806886634045, average MAPE: 4.2491806886634045                                                                                                                                                             \n",
      "Epoch 200/1000, lr: 6.4e-04, average MSE (log10) loss: 4.2507904928557725, average MAPE: 4.2507904928557725                                                                                                                                                             \n",
      "Epoch 201/1000, lr: 6.4e-04, average MSE (log10) loss: 4.242956391159369, average MAPE: 4.242956391159369                                                                                                                                                             \n",
      "Epoch 202/1000, lr: 6.4e-04, average MSE (log10) loss: 4.249061066763741, average MAPE: 4.249061066763741                                                                                                                                                             \n",
      "Epoch 203/1000, lr: 6.4e-04, average MSE (log10) loss: 4.231035977966932, average MAPE: 4.231035977966932                                                                                                                                                             \n",
      "Epoch 204/1000, lr: 6.4e-04, average MSE (log10) loss: 4.259183136297732, average MAPE: 4.259183136297732                                                                                                                                                             \n",
      "Epoch 205/1000, lr: 6.4e-04, average MSE (log10) loss: 4.2262442374716, average MAPE: 4.2262442374716                                                                                                                                                             \n",
      "Epoch 206/1000, lr: 6.4e-04, average MSE (log10) loss: 4.211712490782446, average MAPE: 4.211712490782446                                                                                                                                                             \n",
      "Epoch 207/1000, lr: 6.4e-04, average MSE (log10) loss: 4.239688322495441, average MAPE: 4.239688322495441                                                                                                                                                             \n",
      "Epoch 208/1000, lr: 6.4e-04, average MSE (log10) loss: 4.201515416709745, average MAPE: 4.201515416709745                                                                                                                                                             \n",
      "Epoch 209/1000, lr: 6.4e-04, average MSE (log10) loss: 4.210268366093538, average MAPE: 4.210268366093538                                                                                                                                                             \n",
      "Epoch 210/1000, lr: 6.4e-04, average MSE (log10) loss: 4.214823055267334, average MAPE: 4.214823055267334                                                                                                                                                             \n",
      "Epoch 211/1000, lr: 6.4e-04, average MSE (log10) loss: 4.215437248774937, average MAPE: 4.215437248774937                                                                                                                                                             \n",
      "Epoch 212/1000, lr: 6.4e-04, average MSE (log10) loss: 4.212961218308429, average MAPE: 4.212961218308429                                                                                                                                                             \n",
      "Epoch 213/1000, lr: 6.4e-04, average MSE (log10) loss: 4.224744420148888, average MAPE: 4.224744420148888                                                                                                                                                             \n",
      "Epoch 214/1000, lr: 6.4e-04, average MSE (log10) loss: 4.192952784713434, average MAPE: 4.192952784713434                                                                                                                                                             \n",
      "Epoch 215/1000, lr: 6.4e-04, average MSE (log10) loss: 4.192119592549849, average MAPE: 4.192119592549849                                                                                                                                                             \n",
      "Epoch 216/1000, lr: 6.4e-04, average MSE (log10) loss: 4.191580725689324, average MAPE: 4.191580725689324                                                                                                                                                             \n",
      "Epoch 217/1000, lr: 6.4e-04, average MSE (log10) loss: 4.187382241657802, average MAPE: 4.187382241657802                                                                                                                                                             \n",
      "Epoch 218/1000, lr: 6.4e-04, average MSE (log10) loss: 4.19465482186298, average MAPE: 4.19465482186298                                                                                                                                                             \n",
      "Epoch 219/1000, lr: 6.4e-04, average MSE (log10) loss: 4.184706645109215, average MAPE: 4.184706645109215                                                                                                                                                             \n",
      "Epoch 220/1000, lr: 6.4e-04, average MSE (log10) loss: 4.208057452221306, average MAPE: 4.208057452221306                                                                                                                                                             \n",
      "Epoch 221/1000, lr: 6.4e-04, average MSE (log10) loss: 4.185078039947821, average MAPE: 4.185078039947821                                                                                                                                                             \n",
      "Epoch 222/1000, lr: 6.4e-04, average MSE (log10) loss: 4.174899083740857, average MAPE: 4.174899083740857                                                                                                                                                             \n",
      "Epoch 223/1000, lr: 6.4e-04, average MSE (log10) loss: 4.180027674655525, average MAPE: 4.180027674655525                                                                                                                                                             \n",
      "Epoch 224/1000, lr: 6.4e-04, average MSE (log10) loss: 4.1967811428770725, average MAPE: 4.1967811428770725                                                                                                                                                             \n",
      "Epoch 225/1000, lr: 6.4e-04, average MSE (log10) loss: 4.194505005466695, average MAPE: 4.194505005466695                                                                                                                                                             \n",
      "Epoch 226/1000, lr: 6.4e-04, average MSE (log10) loss: 4.171309007917132, average MAPE: 4.171309007917132                                                                                                                                                             \n",
      "Epoch 227/1000, lr: 6.4e-04, average MSE (log10) loss: 4.168724496997132, average MAPE: 4.168724496997132                                                                                                                                                             \n",
      "Epoch 228/1000, lr: 6.4e-04, average MSE (log10) loss: 4.152393870451013, average MAPE: 4.152393870451013                                                                                                                                                             \n",
      "Epoch 229/1000, lr: 6.4e-04, average MSE (log10) loss: 4.155808002121595, average MAPE: 4.155808002121595                                                                                                                                                             \n",
      "Epoch 230/1000, lr: 6.4e-04, average MSE (log10) loss: 4.16075166585494, average MAPE: 4.16075166585494                                                                                                                                                             \n",
      "Epoch 231/1000, lr: 6.4e-04, average MSE (log10) loss: 4.1499495389510175, average MAPE: 4.1499495389510175                                                                                                                                                             \n",
      "Epoch 232/1000, lr: 6.4e-04, average MSE (log10) loss: 4.146244333228286, average MAPE: 4.146244333228286                                                                                                                                                             \n",
      "Epoch 233/1000, lr: 6.4e-04, average MSE (log10) loss: 4.16442828081092, average MAPE: 4.16442828081092                                                                                                                                                             \n",
      "Epoch 234/1000, lr: 6.4e-04, average MSE (log10) loss: 4.15807189357524, average MAPE: 4.15807189357524                                                                                                                                                             \n",
      "Epoch 235/1000, lr: 6.4e-04, average MSE (log10) loss: 4.155373645315365, average MAPE: 4.155373645315365                                                                                                                                                             \n",
      "Epoch 236/1000, lr: 6.4e-04, average MSE (log10) loss: 4.1432167724687226, average MAPE: 4.1432167724687226                                                                                                                                                             \n",
      "Epoch 237/1000, lr: 6.4e-04, average MSE (log10) loss: 4.1400581058190795, average MAPE: 4.1400581058190795                                                                                                                                                             \n",
      "Epoch 238/1000, lr: 6.4e-04, average MSE (log10) loss: 4.157635593414307, average MAPE: 4.157635593414307                                                                                                                                                             \n",
      "Epoch 239/1000, lr: 6.4e-04, average MSE (log10) loss: 4.144160402064421, average MAPE: 4.144160402064421                                                                                                                                                             \n",
      "Epoch 240/1000, lr: 6.4e-04, average MSE (log10) loss: 4.14477726586011, average MAPE: 4.14477726586011                                                                                                                                                             \n",
      "Epoch 241/1000, lr: 6.4e-04, average MSE (log10) loss: 4.114779261180333, average MAPE: 4.114779261180333                                                                                                                                                             \n",
      "Epoch 242/1000, lr: 6.4e-04, average MSE (log10) loss: 4.113255042445903, average MAPE: 4.113255042445903                                                                                                                                                             \n",
      "Epoch 243/1000, lr: 6.4e-04, average MSE (log10) loss: 4.1163341707112835, average MAPE: 4.1163341707112835                                                                                                                                                             \n",
      "Epoch 244/1000, lr: 6.4e-04, average MSE (log10) loss: 4.1362392162790105, average MAPE: 4.1362392162790105                                                                                                                                                             \n",
      "Epoch 245/1000, lr: 6.4e-04, average MSE (log10) loss: 4.127757704987818, average MAPE: 4.127757704987818                                                                                                                                                             \n",
      "Epoch 246/1000, lr: 6.4e-04, average MSE (log10) loss: 4.115136528015137, average MAPE: 4.115136528015137                                                                                                                                                             \n",
      "Epoch 247/1000, lr: 6.4e-04, average MSE (log10) loss: 4.128966715871071, average MAPE: 4.128966715871071                                                                                                                                                             \n",
      "Epoch 248/1000, lr: 5.1e-04, average MSE (log10) loss: 4.092952493745454, average MAPE: 4.092952493745454                                                                                                                                                             \n",
      "Epoch 249/1000, lr: 5.1e-04, average MSE (log10) loss: 4.085894357914827, average MAPE: 4.085894357914827                                                                                                                                                             \n",
      "Epoch 250/1000, lr: 5.1e-04, average MSE (log10) loss: 4.092032199976396, average MAPE: 4.092032199976396                                                                                                                                                             \n",
      "Epoch 251/1000, lr: 5.1e-04, average MSE (log10) loss: 4.078017844959181, average MAPE: 4.078017844959181                                                                                                                                                             \n",
      "Epoch 252/1000, lr: 5.1e-04, average MSE (log10) loss: 4.085716941405316, average MAPE: 4.085716941405316                                                                                                                                                             \n",
      "Epoch 253/1000, lr: 5.1e-04, average MSE (log10) loss: 4.084471465130242, average MAPE: 4.084471465130242                                                                                                                                                             \n",
      "Epoch 254/1000, lr: 5.1e-04, average MSE (log10) loss: 4.079971014723486, average MAPE: 4.079971014723486                                                                                                                                                             \n",
      "Epoch 255/1000, lr: 5.1e-04, average MSE (log10) loss: 4.089573411552274, average MAPE: 4.089573411552274                                                                                                                                                             \n",
      "Epoch 256/1000, lr: 5.1e-04, average MSE (log10) loss: 4.082671477843304, average MAPE: 4.082671477843304                                                                                                                                                             \n",
      "Epoch 257/1000, lr: 5.1e-04, average MSE (log10) loss: 4.073650533325818, average MAPE: 4.073650533325818                                                                                                                                                             \n",
      "Epoch 258/1000, lr: 5.1e-04, average MSE (log10) loss: 4.073954256213441, average MAPE: 4.073954256213441                                                                                                                                                             \n",
      "Epoch 259/1000, lr: 5.1e-04, average MSE (log10) loss: 4.070864033212467, average MAPE: 4.070864033212467                                                                                                                                                             \n",
      "Epoch 260/1000, lr: 5.1e-04, average MSE (log10) loss: 4.079644175938197, average MAPE: 4.079644175938197                                                                                                                                                             \n",
      "Epoch 261/1000, lr: 5.1e-04, average MSE (log10) loss: 4.081737660388558, average MAPE: 4.081737660388558                                                                                                                                                             \n",
      "Epoch 262/1000, lr: 5.1e-04, average MSE (log10) loss: 4.07802632195609, average MAPE: 4.07802632195609                                                                                                                                                             \n",
      "Epoch 263/1000, lr: 5.1e-04, average MSE (log10) loss: 4.057930926887357, average MAPE: 4.057930926887357                                                                                                                                                             \n",
      "Epoch 264/1000, lr: 5.1e-04, average MSE (log10) loss: 4.09010477747236, average MAPE: 4.09010477747236                                                                                                                                                             \n",
      "Epoch 265/1000, lr: 5.1e-04, average MSE (log10) loss: 4.0630234552889455, average MAPE: 4.0630234552889455                                                                                                                                                             \n",
      "Epoch 266/1000, lr: 5.1e-04, average MSE (log10) loss: 4.060149920716578, average MAPE: 4.060149920716578                                                                                                                                                             \n",
      "Epoch 267/1000, lr: 5.1e-04, average MSE (log10) loss: 4.063222776140486, average MAPE: 4.063222776140486                                                                                                                                                             \n",
      "Epoch 268/1000, lr: 4.1e-04, average MSE (log10) loss: 4.0418847998794245, average MAPE: 4.0418847998794245                                                                                                                                                             \n",
      "Epoch 269/1000, lr: 4.1e-04, average MSE (log10) loss: 4.033812869324976, average MAPE: 4.033812869324976                                                                                                                                                             \n",
      "Epoch 270/1000, lr: 4.1e-04, average MSE (log10) loss: 4.035469369499051, average MAPE: 4.035469369499051                                                                                                                                                             \n",
      "Epoch 271/1000, lr: 4.1e-04, average MSE (log10) loss: 4.031648891799304, average MAPE: 4.031648891799304                                                                                                                                                             \n",
      "Epoch 272/1000, lr: 4.1e-04, average MSE (log10) loss: 4.026983453789536, average MAPE: 4.026983453789536                                                                                                                                                             \n",
      "Epoch 273/1000, lr: 4.1e-04, average MSE (log10) loss: 4.029446639820021, average MAPE: 4.029446639820021                                                                                                                                                             \n",
      "Epoch 274/1000, lr: 4.1e-04, average MSE (log10) loss: 4.038689099525919, average MAPE: 4.038689099525919                                                                                                                                                             \n",
      "Epoch 275/1000, lr: 4.1e-04, average MSE (log10) loss: 4.036875189567099, average MAPE: 4.036875189567099                                                                                                                                                             \n",
      "Epoch 276/1000, lr: 4.1e-04, average MSE (log10) loss: 4.027347790465063, average MAPE: 4.027347790465063                                                                                                                                                             \n",
      "Epoch 277/1000, lr: 4.1e-04, average MSE (log10) loss: 4.0273899389773, average MAPE: 4.0273899389773                                                                                                                                                             \n",
      "Epoch 278/1000, lr: 4.1e-04, average MSE (log10) loss: 4.019532870273201, average MAPE: 4.019532870273201                                                                                                                                                             \n",
      "Epoch 279/1000, lr: 4.1e-04, average MSE (log10) loss: 4.03534459094612, average MAPE: 4.03534459094612                                                                                                                                                             \n",
      "Epoch 280/1000, lr: 4.1e-04, average MSE (log10) loss: 4.0142147482657915, average MAPE: 4.0142147482657915                                                                                                                                                             \n",
      "Epoch 281/1000, lr: 4.1e-04, average MSE (log10) loss: 4.027344421464569, average MAPE: 4.027344421464569                                                                                                                                                             \n",
      "Epoch 282/1000, lr: 4.1e-04, average MSE (log10) loss: 4.012934770389479, average MAPE: 4.012934770389479                                                                                                                                                             \n",
      "Epoch 283/1000, lr: 4.1e-04, average MSE (log10) loss: 4.021432840580843, average MAPE: 4.021432840580843                                                                                                                                                             \n",
      "Epoch 284/1000, lr: 4.1e-04, average MSE (log10) loss: 4.007592265459956, average MAPE: 4.007592265459956                                                                                                                                                             \n",
      "Epoch 285/1000, lr: 4.1e-04, average MSE (log10) loss: 4.005572747211067, average MAPE: 4.005572747211067                                                                                                                                                             \n",
      "Epoch 286/1000, lr: 4.1e-04, average MSE (log10) loss: 4.016185090979751, average MAPE: 4.016185090979751                                                                                                                                                             \n",
      "Epoch 287/1000, lr: 4.1e-04, average MSE (log10) loss: 4.012542290590248, average MAPE: 4.012542290590248                                                                                                                                                             \n",
      "Epoch 288/1000, lr: 4.1e-04, average MSE (log10) loss: 4.015580550018622, average MAPE: 4.015580550018622                                                                                                                                                             \n",
      "Epoch 289/1000, lr: 3.3e-04, average MSE (log10) loss: 3.994275611760665, average MAPE: 3.994275611760665                                                                                                                                                             \n",
      "Epoch 290/1000, lr: 3.3e-04, average MSE (log10) loss: 3.9833546336816283, average MAPE: 3.9833546336816283                                                                                                                                                             \n",
      "Epoch 291/1000, lr: 3.3e-04, average MSE (log10) loss: 3.985982085247429, average MAPE: 3.985982085247429                                                                                                                                                             \n",
      "Epoch 292/1000, lr: 3.3e-04, average MSE (log10) loss: 3.9855440976668377, average MAPE: 3.9855440976668377                                                                                                                                                             \n",
      "Epoch 293/1000, lr: 3.3e-04, average MSE (log10) loss: 3.996408769062587, average MAPE: 3.996408769062587                                                                                                                                                             \n",
      "Epoch 294/1000, lr: 3.3e-04, average MSE (log10) loss: 3.9828569295454996, average MAPE: 3.9828569295454996                                                                                                                                                             \n",
      "Epoch 295/1000, lr: 3.3e-04, average MSE (log10) loss: 3.9900191063783605, average MAPE: 3.9900191063783605                                                                                                                                                             \n",
      "Epoch 296/1000, lr: 3.3e-04, average MSE (log10) loss: 3.9790173082935567, average MAPE: 3.9790173082935567                                                                                                                                                             \n",
      "Epoch 297/1000, lr: 3.3e-04, average MSE (log10) loss: 3.9912236622401647, average MAPE: 3.9912236622401647                                                                                                                                                             \n",
      "Epoch 298/1000, lr: 3.3e-04, average MSE (log10) loss: 3.986792906936334, average MAPE: 3.986792906936334                                                                                                                                                             \n",
      "Epoch 299/1000, lr: 3.3e-04, average MSE (log10) loss: 3.9761271642178904, average MAPE: 3.9761271642178904                                                                                                                                                             \n",
      "Epoch 300/1000, lr: 3.3e-04, average MSE (log10) loss: 3.979887681104699, average MAPE: 3.979887681104699                                                                                                                                                             \n",
      "Epoch 301/1000, lr: 3.3e-04, average MSE (log10) loss: 3.977685698684381, average MAPE: 3.977685698684381                                                                                                                                                             \n",
      "Epoch 302/1000, lr: 3.3e-04, average MSE (log10) loss: 3.9806809571324564, average MAPE: 3.9806809571324564                                                                                                                                                             \n",
      "Epoch 303/1000, lr: 3.3e-04, average MSE (log10) loss: 3.975202938001983, average MAPE: 3.975202938001983                                                                                                                                                             \n",
      "Epoch 304/1000, lr: 3.3e-04, average MSE (log10) loss: 3.9697311177545664, average MAPE: 3.9697311177545664                                                                                                                                                             \n",
      "Epoch 305/1000, lr: 3.3e-04, average MSE (log10) loss: 3.9801465949233696, average MAPE: 3.9801465949233696                                                                                                                                                             \n",
      "Epoch 306/1000, lr: 3.3e-04, average MSE (log10) loss: 3.961612300483548, average MAPE: 3.961612300483548                                                                                                                                                             \n",
      "Epoch 307/1000, lr: 3.3e-04, average MSE (log10) loss: 3.9723507414058763, average MAPE: 3.9723507414058763                                                                                                                                                             \n",
      "Epoch 308/1000, lr: 3.3e-04, average MSE (log10) loss: 3.965802256915034, average MAPE: 3.965802256915034                                                                                                                                                             \n",
      "Epoch 309/1000, lr: 2.6e-04, average MSE (log10) loss: 3.9621099257955747, average MAPE: 3.9621099257955747                                                                                                                                                             \n",
      "Epoch 310/1000, lr: 2.6e-04, average MSE (log10) loss: 3.965769319145047, average MAPE: 3.965769319145047                                                                                                                                                             \n",
      "Epoch 311/1000, lr: 2.6e-04, average MSE (log10) loss: 3.955089877576244, average MAPE: 3.955089877576244                                                                                                                                                             \n",
      "Epoch 312/1000, lr: 2.6e-04, average MSE (log10) loss: 3.954784315459582, average MAPE: 3.954784315459582                                                                                                                                                             \n",
      "Epoch 313/1000, lr: 2.6e-04, average MSE (log10) loss: 3.944185359137399, average MAPE: 3.944185359137399                                                                                                                                                             \n",
      "Epoch 314/1000, lr: 2.6e-04, average MSE (log10) loss: 3.9493966910303855, average MAPE: 3.9493966910303855                                                                                                                                                             \n",
      "Epoch 315/1000, lr: 2.6e-04, average MSE (log10) loss: 3.9511605360070052, average MAPE: 3.9511605360070052                                                                                                                                                             \n",
      "Epoch 316/1000, lr: 2.6e-04, average MSE (log10) loss: 3.9572592307110224, average MAPE: 3.9572592307110224                                                                                                                                                             \n",
      "Epoch 317/1000, lr: 2.6e-04, average MSE (log10) loss: 3.949023016131654, average MAPE: 3.949023016131654                                                                                                                                                             \n",
      "Epoch 318/1000, lr: 2.6e-04, average MSE (log10) loss: 3.9490759615995445, average MAPE: 3.9490759615995445                                                                                                                                                             \n",
      "Epoch 319/1000, lr: 2.6e-04, average MSE (log10) loss: 3.9434936737527653, average MAPE: 3.9434936737527653                                                                                                                                                             \n",
      "Epoch 320/1000, lr: 2.6e-04, average MSE (log10) loss: 3.9378833323108906, average MAPE: 3.9378833323108906                                                                                                                                                             \n",
      "Epoch 321/1000, lr: 2.6e-04, average MSE (log10) loss: 3.9383963507048936, average MAPE: 3.9383963507048936                                                                                                                                                             \n",
      "Epoch 322/1000, lr: 2.6e-04, average MSE (log10) loss: 3.940085374092569, average MAPE: 3.940085374092569                                                                                                                                                             \n",
      "Epoch 323/1000, lr: 2.6e-04, average MSE (log10) loss: 3.940670825997177, average MAPE: 3.940670825997177                                                                                                                                                             \n",
      "Epoch 324/1000, lr: 2.6e-04, average MSE (log10) loss: 3.9373122555868965, average MAPE: 3.9373122555868965                                                                                                                                                             \n",
      "Epoch 325/1000, lr: 2.6e-04, average MSE (log10) loss: 3.9369815271727893, average MAPE: 3.9369815271727893                                                                                                                                                             \n",
      "Epoch 326/1000, lr: 2.6e-04, average MSE (log10) loss: 3.9329662780372465, average MAPE: 3.9329662780372465                                                                                                                                                             \n",
      "Epoch 327/1000, lr: 2.6e-04, average MSE (log10) loss: 3.9400167572255036, average MAPE: 3.9400167572255036                                                                                                                                                             \n",
      "Epoch 328/1000, lr: 2.6e-04, average MSE (log10) loss: 3.9344739125699415, average MAPE: 3.9344739125699415                                                                                                                                                             \n",
      "Epoch 329/1000, lr: 2.6e-04, average MSE (log10) loss: 3.9317263778375118, average MAPE: 3.9317263778375118                                                                                                                                                             \n",
      "Epoch 330/1000, lr: 2.1e-04, average MSE (log10) loss: 3.9208454258587895, average MAPE: 3.9208454258587895                                                                                                                                                             \n",
      "Epoch 331/1000, lr: 2.1e-04, average MSE (log10) loss: 3.925881615463568, average MAPE: 3.925881615463568                                                                                                                                                             \n",
      "Epoch 332/1000, lr: 2.1e-04, average MSE (log10) loss: 3.9261234263984526, average MAPE: 3.9261234263984526                                                                                                                                                             \n",
      "Epoch 333/1000, lr: 2.1e-04, average MSE (log10) loss: 3.915554125454961, average MAPE: 3.915554125454961                                                                                                                                                             \n",
      "Epoch 334/1000, lr: 2.1e-04, average MSE (log10) loss: 3.9181288631594913, average MAPE: 3.9181288631594913                                                                                                                                                             \n",
      "Epoch 335/1000, lr: 2.1e-04, average MSE (log10) loss: 3.9191653572783176, average MAPE: 3.9191653572783176                                                                                                                                                             \n",
      "Epoch 336/1000, lr: 2.1e-04, average MSE (log10) loss: 3.9160791844737775, average MAPE: 3.9160791844737775                                                                                                                                                             \n",
      "Epoch 337/1000, lr: 2.1e-04, average MSE (log10) loss: 3.9162875662044603, average MAPE: 3.9162875662044603                                                                                                                                                             \n",
      "Epoch 338/1000, lr: 2.1e-04, average MSE (log10) loss: 3.913371074442961, average MAPE: 3.913371074442961                                                                                                                                                             \n",
      "Epoch 339/1000, lr: 2.1e-04, average MSE (log10) loss: 3.918579996848593, average MAPE: 3.918579996848593                                                                                                                                                             \n",
      "Epoch 340/1000, lr: 2.1e-04, average MSE (log10) loss: 3.9104230228735477, average MAPE: 3.9104230228735477                                                                                                                                                             \n",
      "Epoch 341/1000, lr: 2.1e-04, average MSE (log10) loss: 3.9156819927449127, average MAPE: 3.9156819927449127                                                                                                                                                             \n",
      "Epoch 342/1000, lr: 2.1e-04, average MSE (log10) loss: 3.9140206298049613, average MAPE: 3.9140206298049613                                                                                                                                                             \n",
      "Epoch 343/1000, lr: 2.1e-04, average MSE (log10) loss: 3.9094282481135156, average MAPE: 3.9094282481135156                                                                                                                                                             \n",
      "Epoch 344/1000, lr: 2.1e-04, average MSE (log10) loss: 3.9061663034010907, average MAPE: 3.9061663034010907                                                                                                                                                             \n",
      "Epoch 345/1000, lr: 2.1e-04, average MSE (log10) loss: 3.907025636945452, average MAPE: 3.907025636945452                                                                                                                                                             \n",
      "Epoch 346/1000, lr: 2.1e-04, average MSE (log10) loss: 3.9163910418140646, average MAPE: 3.9163910418140646                                                                                                                                                             \n",
      "Epoch 347/1000, lr: 2.1e-04, average MSE (log10) loss: 3.9121138446185055, average MAPE: 3.9121138446185055                                                                                                                                                             \n",
      "Epoch 348/1000, lr: 2.1e-04, average MSE (log10) loss: 3.901694716239462, average MAPE: 3.901694716239462                                                                                                                                                             \n",
      "Epoch 349/1000, lr: 2.1e-04, average MSE (log10) loss: 3.9065407042600673, average MAPE: 3.9065407042600673                                                                                                                                                             \n",
      "Epoch 350/1000, lr: 1.7e-04, average MSE (log10) loss: 3.9029110139730023, average MAPE: 3.9029110139730023                                                                                                                                                             \n",
      "Epoch 351/1000, lr: 1.7e-04, average MSE (log10) loss: 3.89250354669532, average MAPE: 3.89250354669532                                                                                                                                                             \n",
      "Epoch 352/1000, lr: 1.7e-04, average MSE (log10) loss: 3.8918320597434533, average MAPE: 3.8918320597434533                                                                                                                                                             \n",
      "Epoch 353/1000, lr: 1.7e-04, average MSE (log10) loss: 3.8930465610659852, average MAPE: 3.8930465610659852                                                                                                                                                             \n",
      "Epoch 354/1000, lr: 1.7e-04, average MSE (log10) loss: 3.892617776442547, average MAPE: 3.892617776442547                                                                                                                                                             \n",
      "Epoch 355/1000, lr: 1.7e-04, average MSE (log10) loss: 3.895855677857691, average MAPE: 3.895855677857691                                                                                                                                                             \n",
      "Epoch 356/1000, lr: 1.7e-04, average MSE (log10) loss: 3.892926108107275, average MAPE: 3.892926108107275                                                                                                                                                             \n",
      "Epoch 357/1000, lr: 1.7e-04, average MSE (log10) loss: 3.895708623224375, average MAPE: 3.895708623224375                                                                                                                                                             \n",
      "Epoch 358/1000, lr: 1.7e-04, average MSE (log10) loss: 3.89129866872515, average MAPE: 3.89129866872515                                                                                                                                                             \n",
      "Epoch 359/1000, lr: 1.7e-04, average MSE (log10) loss: 3.890173289240623, average MAPE: 3.890173289240623                                                                                                                                                             \n",
      "Epoch 360/1000, lr: 1.7e-04, average MSE (log10) loss: 3.8896498310322665, average MAPE: 3.8896498310322665                                                                                                                                                             \n",
      "Epoch 361/1000, lr: 1.7e-04, average MSE (log10) loss: 3.892064784497631, average MAPE: 3.892064784497631                                                                                                                                                             \n",
      "Epoch 362/1000, lr: 1.7e-04, average MSE (log10) loss: 3.8869643707664645, average MAPE: 3.8869643707664645                                                                                                                                                             \n",
      "Epoch 363/1000, lr: 1.7e-04, average MSE (log10) loss: 3.88442099045734, average MAPE: 3.88442099045734                                                                                                                                                             \n",
      "Epoch 364/1000, lr: 1.7e-04, average MSE (log10) loss: 3.8838138268918407, average MAPE: 3.8838138268918407                                                                                                                                                             \n",
      "Epoch 365/1000, lr: 1.7e-04, average MSE (log10) loss: 3.8928573034247576, average MAPE: 3.8928573034247576                                                                                                                                                             \n",
      "Epoch 366/1000, lr: 1.7e-04, average MSE (log10) loss: 3.883419643129621, average MAPE: 3.883419643129621                                                                                                                                                             \n",
      "Epoch 367/1000, lr: 1.7e-04, average MSE (log10) loss: 3.881470789228167, average MAPE: 3.881470789228167                                                                                                                                                             \n",
      "Epoch 368/1000, lr: 1.7e-04, average MSE (log10) loss: 3.881177976180096, average MAPE: 3.881177976180096                                                                                                                                                             \n",
      "Epoch 369/1000, lr: 1.7e-04, average MSE (log10) loss: 3.878047074103842, average MAPE: 3.878047074103842                                                                                                                                                             \n",
      "Epoch 370/1000, lr: 1.7e-04, average MSE (log10) loss: 3.878787306376866, average MAPE: 3.878787306376866                                                                                                                                                             \n",
      "Epoch 371/1000, lr: 1.7e-04, average MSE (log10) loss: 3.8838076484446624, average MAPE: 3.8838076484446624                                                                                                                                                             \n",
      "Epoch 372/1000, lr: 1.7e-04, average MSE (log10) loss: 3.87646658663847, average MAPE: 3.87646658663847                                                                                                                                                             \n",
      "Epoch 373/1000, lr: 1.7e-04, average MSE (log10) loss: 3.8776818207332067, average MAPE: 3.8776818207332067                                                                                                                                                             \n",
      "Epoch 374/1000, lr: 1.3e-04, average MSE (log10) loss: 3.8738744803837366, average MAPE: 3.8738744803837366                                                                                                                                                             \n",
      "Epoch 375/1000, lr: 1.3e-04, average MSE (log10) loss: 3.867454594008777, average MAPE: 3.867454594008777                                                                                                                                                             \n",
      "Epoch 376/1000, lr: 1.3e-04, average MSE (log10) loss: 3.8716806791266616, average MAPE: 3.8716806791266616                                                                                                                                                             \n",
      "Epoch 377/1000, lr: 1.3e-04, average MSE (log10) loss: 3.868367234054877, average MAPE: 3.868367234054877                                                                                                                                                             \n",
      "Epoch 378/1000, lr: 1.3e-04, average MSE (log10) loss: 3.867002871571755, average MAPE: 3.867002871571755                                                                                                                                                             \n",
      "Epoch 379/1000, lr: 1.3e-04, average MSE (log10) loss: 3.8669660140057, average MAPE: 3.8669660140057                                                                                                                                                             \n",
      "Epoch 380/1000, lr: 1.3e-04, average MSE (log10) loss: 3.869190870985693, average MAPE: 3.869190870985693                                                                                                                                                             \n",
      "Epoch 381/1000, lr: 1.3e-04, average MSE (log10) loss: 3.866504767476296, average MAPE: 3.866504767476296                                                                                                                                                             \n",
      "Epoch 382/1000, lr: 1.3e-04, average MSE (log10) loss: 3.8690823885859276, average MAPE: 3.8690823885859276                                                                                                                                                             \n",
      "Epoch 383/1000, lr: 1.3e-04, average MSE (log10) loss: 3.8630282294993497, average MAPE: 3.8630282294993497                                                                                                                                                             \n",
      "Epoch 384/1000, lr: 1.3e-04, average MSE (log10) loss: 3.863862270238448, average MAPE: 3.863862270238448                                                                                                                                                             \n",
      "Epoch 385/1000, lr: 1.3e-04, average MSE (log10) loss: 3.8619957515171595, average MAPE: 3.8619957515171595                                                                                                                                                             \n",
      "Epoch 386/1000, lr: 1.3e-04, average MSE (log10) loss: 3.86628098487854, average MAPE: 3.86628098487854                                                                                                                                                             \n",
      "Epoch 387/1000, lr: 1.3e-04, average MSE (log10) loss: 3.866966642652239, average MAPE: 3.866966642652239                                                                                                                                                             \n",
      "Epoch 388/1000, lr: 1.3e-04, average MSE (log10) loss: 3.8644011906215123, average MAPE: 3.8644011906215123                                                                                                                                                             \n",
      "Epoch 389/1000, lr: 1.3e-04, average MSE (log10) loss: 3.856838096891131, average MAPE: 3.856838096891131                                                                                                                                                             \n",
      "Epoch 390/1000, lr: 1.3e-04, average MSE (log10) loss: 3.8592595129596945, average MAPE: 3.8592595129596945                                                                                                                                                             \n",
      "Epoch 391/1000, lr: 1.3e-04, average MSE (log10) loss: 3.8550677124334842, average MAPE: 3.8550677124334842                                                                                                                                                             \n",
      "Epoch 392/1000, lr: 1.3e-04, average MSE (log10) loss: 3.8611554642112886, average MAPE: 3.8611554642112886                                                                                                                                                             \n",
      "Epoch 393/1000, lr: 1.3e-04, average MSE (log10) loss: 3.857372993352462, average MAPE: 3.857372993352462                                                                                                                                                             \n",
      "Epoch 394/1000, lr: 1.3e-04, average MSE (log10) loss: 3.8695686729586853, average MAPE: 3.8695686729586853                                                                                                                                                             \n",
      "Epoch 395/1000, lr: 1.3e-04, average MSE (log10) loss: 3.858151501052234, average MAPE: 3.858151501052234                                                                                                                                                             \n",
      "Epoch 396/1000, lr: 1.3e-04, average MSE (log10) loss: 3.8559619582429225, average MAPE: 3.8559619582429225                                                                                                                                                             \n",
      "Epoch 397/1000, lr: 1.3e-04, average MSE (log10) loss: 3.855706602213334, average MAPE: 3.855706602213334                                                                                                                                                             \n",
      "Epoch 398/1000, lr: 1.3e-04, average MSE (log10) loss: 3.858301823479789, average MAPE: 3.858301823479789                                                                                                                                                             \n",
      "Epoch 399/1000, lr: 1.3e-04, average MSE (log10) loss: 3.854154333776357, average MAPE: 3.854154333776357                                                                                                                                                             \n",
      "Epoch 400/1000, lr: 1.3e-04, average MSE (log10) loss: 3.8525125931720345, average MAPE: 3.8525125931720345                                                                                                                                                             \n",
      "Epoch 401/1000, lr: 1.3e-04, average MSE (log10) loss: 3.8526927792296117, average MAPE: 3.8526927792296117                                                                                                                                                             \n",
      "Epoch 402/1000, lr: 1.3e-04, average MSE (log10) loss: 3.8543153801742864, average MAPE: 3.8543153801742864                                                                                                                                                             \n",
      "Epoch 403/1000, lr: 1.3e-04, average MSE (log10) loss: 3.8486736686862244, average MAPE: 3.8486736686862244                                                                                                                                                             \n",
      "Epoch 404/1000, lr: 1.3e-04, average MSE (log10) loss: 3.857124406464246, average MAPE: 3.857124406464246                                                                                                                                                             \n",
      "Epoch 405/1000, lr: 1.3e-04, average MSE (log10) loss: 3.8498641160069678, average MAPE: 3.8498641160069678                                                                                                                                                             \n",
      "Epoch 406/1000, lr: 1.3e-04, average MSE (log10) loss: 3.85224154628053, average MAPE: 3.85224154628053                                                                                                                                                             \n",
      "Epoch 407/1000, lr: 1.3e-04, average MSE (log10) loss: 3.848941772811267, average MAPE: 3.848941772811267                                                                                                                                                             \n",
      "Epoch 408/1000, lr: 1.3e-04, average MSE (log10) loss: 3.8516195550256844, average MAPE: 3.8516195550256844                                                                                                                                                             \n",
      "Epoch 409/1000, lr: 1.3e-04, average MSE (log10) loss: 3.8472502289986124, average MAPE: 3.8472502289986124                                                                                                                                                             \n",
      "Epoch 410/1000, lr: 1.1e-04, average MSE (log10) loss: 3.8434170557528127, average MAPE: 3.8434170557528127                                                                                                                                                             \n",
      "Epoch 411/1000, lr: 1.1e-04, average MSE (log10) loss: 3.8433405010067685, average MAPE: 3.8433405010067685                                                                                                                                                             \n",
      "Epoch 412/1000, lr: 1.1e-04, average MSE (log10) loss: 3.8381536746511653, average MAPE: 3.8381536746511653                                                                                                                                                             \n",
      "Epoch 413/1000, lr: 1.1e-04, average MSE (log10) loss: 3.840519986833845, average MAPE: 3.840519986833845                                                                                                                                                             \n",
      "Epoch 414/1000, lr: 1.1e-04, average MSE (log10) loss: 3.840829122309782, average MAPE: 3.840829122309782                                                                                                                                                             \n",
      "Epoch 415/1000, lr: 1.1e-04, average MSE (log10) loss: 3.836939917778482, average MAPE: 3.836939917778482                                                                                                                                                             \n",
      "Epoch 416/1000, lr: 1.1e-04, average MSE (log10) loss: 3.837149797167097, average MAPE: 3.837149797167097                                                                                                                                                             \n",
      "Epoch 417/1000, lr: 1.1e-04, average MSE (log10) loss: 3.8399301859797266, average MAPE: 3.8399301859797266                                                                                                                                                             \n",
      "Epoch 418/1000, lr: 1.1e-04, average MSE (log10) loss: 3.8408071138420885, average MAPE: 3.8408071138420885                                                                                                                                                             \n",
      "Epoch 419/1000, lr: 1.1e-04, average MSE (log10) loss: 3.841057133188053, average MAPE: 3.841057133188053                                                                                                                                                             \n",
      "Epoch 420/1000, lr: 1.1e-04, average MSE (log10) loss: 3.835614588795876, average MAPE: 3.835614588795876                                                                                                                                                             \n",
      "Epoch 421/1000, lr: 1.1e-04, average MSE (log10) loss: 3.8369178265941386, average MAPE: 3.8369178265941386                                                                                                                                                             \n",
      "Epoch 422/1000, lr: 1.1e-04, average MSE (log10) loss: 3.8353853293827602, average MAPE: 3.8353853293827602                                                                                                                                                             \n",
      "Epoch 423/1000, lr: 1.1e-04, average MSE (log10) loss: 3.8367372931266317, average MAPE: 3.8367372931266317                                                                                                                                                             \n",
      "Epoch 424/1000, lr: 1.1e-04, average MSE (log10) loss: 3.837074493875309, average MAPE: 3.837074493875309                                                                                                                                                             \n",
      "Epoch 425/1000, lr: 1.1e-04, average MSE (log10) loss: 3.8359547712364974, average MAPE: 3.8359547712364974                                                                                                                                                             \n",
      "Epoch 426/1000, lr: 1.1e-04, average MSE (log10) loss: 3.8348070241967025, average MAPE: 3.8348070241967025                                                                                                                                                             \n",
      "Epoch 427/1000, lr: 1.1e-04, average MSE (log10) loss: 3.8327186535815803, average MAPE: 3.8327186535815803                                                                                                                                                             \n",
      "Epoch 428/1000, lr: 1.1e-04, average MSE (log10) loss: 3.829704898717452, average MAPE: 3.829704898717452                                                                                                                                                             \n",
      "Epoch 429/1000, lr: 1.1e-04, average MSE (log10) loss: 3.8322284338425616, average MAPE: 3.8322284338425616                                                                                                                                                             \n",
      "Epoch 430/1000, lr: 8.6e-05, average MSE (log10) loss: 3.83948337301916, average MAPE: 3.83948337301916                                                                                                                                                             \n",
      "Epoch 431/1000, lr: 8.6e-05, average MSE (log10) loss: 3.8264880131702035, average MAPE: 3.8264880131702035                                                                                                                                                             \n",
      "Epoch 432/1000, lr: 8.6e-05, average MSE (log10) loss: 3.824247556803178, average MAPE: 3.824247556803178                                                                                                                                                             \n",
      "Epoch 433/1000, lr: 8.6e-05, average MSE (log10) loss: 3.823061639435437, average MAPE: 3.823061639435437                                                                                                                                                             \n",
      "Epoch 434/1000, lr: 8.6e-05, average MSE (log10) loss: 3.8217696802956715, average MAPE: 3.8217696802956715                                                                                                                                                             \n",
      "Epoch 435/1000, lr: 8.6e-05, average MSE (log10) loss: 3.8272588223827126, average MAPE: 3.8272588223827126                                                                                                                                                             \n",
      "Epoch 436/1000, lr: 8.6e-05, average MSE (log10) loss: 3.825061935308028, average MAPE: 3.825061935308028                                                                                                                                                             \n",
      "Epoch 437/1000, lr: 8.6e-05, average MSE (log10) loss: 3.8236898811496034, average MAPE: 3.8236898811496034                                                                                                                                                             \n",
      "Epoch 438/1000, lr: 8.6e-05, average MSE (log10) loss: 3.8225265103943493, average MAPE: 3.8225265103943493                                                                                                                                                             \n",
      "Epoch 439/1000, lr: 8.6e-05, average MSE (log10) loss: 3.8229166497989575, average MAPE: 3.8229166497989575                                                                                                                                                             \n",
      "Epoch 440/1000, lr: 8.6e-05, average MSE (log10) loss: 3.8286497534537802, average MAPE: 3.8286497534537802                                                                                                                                                             \n",
      "Epoch 441/1000, lr: 8.6e-05, average MSE (log10) loss: 3.823432546732377, average MAPE: 3.823432546732377                                                                                                                                                             \n",
      "Epoch 442/1000, lr: 8.6e-05, average MSE (log10) loss: 3.823606214717943, average MAPE: 3.823606214717943                                                                                                                                                             \n",
      "Epoch 443/1000, lr: 8.6e-05, average MSE (log10) loss: 3.8214329174586705, average MAPE: 3.8214329174586705                                                                                                                                                             \n",
      "Epoch 444/1000, lr: 8.6e-05, average MSE (log10) loss: 3.8205493109566824, average MAPE: 3.8205493109566824                                                                                                                                                             \n",
      "Epoch 445/1000, lr: 8.6e-05, average MSE (log10) loss: 3.8211892994082706, average MAPE: 3.8211892994082706                                                                                                                                                             \n",
      "Epoch 446/1000, lr: 8.6e-05, average MSE (log10) loss: 3.820220996895615, average MAPE: 3.820220996895615                                                                                                                                                             \n",
      "Epoch 447/1000, lr: 8.6e-05, average MSE (log10) loss: 3.817804553557415, average MAPE: 3.817804553557415                                                                                                                                                             \n",
      "Epoch 448/1000, lr: 8.6e-05, average MSE (log10) loss: 3.8212459778299137, average MAPE: 3.8212459778299137                                                                                                                                                             \n",
      "Epoch 449/1000, lr: 8.6e-05, average MSE (log10) loss: 3.8195112617648377, average MAPE: 3.8195112617648377                                                                                                                                                             \n",
      "Epoch 450/1000, lr: 8.6e-05, average MSE (log10) loss: 3.8231351657789583, average MAPE: 3.8231351657789583                                                                                                                                                             \n",
      "Epoch 451/1000, lr: 8.6e-05, average MSE (log10) loss: 3.8161791850109488, average MAPE: 3.8161791850109488                                                                                                                                                             \n",
      "Epoch 452/1000, lr: 8.6e-05, average MSE (log10) loss: 3.819420369790525, average MAPE: 3.819420369790525                                                                                                                                                             \n",
      "Epoch 453/1000, lr: 8.6e-05, average MSE (log10) loss: 3.8172597213667268, average MAPE: 3.8172597213667268                                                                                                                                                             \n",
      "Epoch 454/1000, lr: 8.6e-05, average MSE (log10) loss: 3.815589395834475, average MAPE: 3.815589395834475                                                                                                                                                             \n",
      "Epoch 455/1000, lr: 8.6e-05, average MSE (log10) loss: 3.8176390667350923, average MAPE: 3.8176390667350923                                                                                                                                                             \n",
      "Epoch 456/1000, lr: 8.6e-05, average MSE (log10) loss: 3.814241278901392, average MAPE: 3.814241278901392                                                                                                                                                             \n",
      "Epoch 457/1000, lr: 8.6e-05, average MSE (log10) loss: 3.8169859769392986, average MAPE: 3.8169859769392986                                                                                                                                                             \n",
      "Epoch 458/1000, lr: 8.6e-05, average MSE (log10) loss: 3.814790150584007, average MAPE: 3.814790150584007                                                                                                                                                             \n",
      "Epoch 459/1000, lr: 8.6e-05, average MSE (log10) loss: 3.8145816802978514, average MAPE: 3.8145816802978514                                                                                                                                                             \n",
      "Epoch 460/1000, lr: 8.6e-05, average MSE (log10) loss: 3.813077252251761, average MAPE: 3.813077252251761                                                                                                                                                             \n",
      "Epoch 461/1000, lr: 8.6e-05, average MSE (log10) loss: 3.814120421117666, average MAPE: 3.814120421117666                                                                                                                                                             \n",
      "Epoch 462/1000, lr: 8.6e-05, average MSE (log10) loss: 3.8121019567762104, average MAPE: 3.8121019567762104                                                                                                                                                             \n",
      "Epoch 463/1000, lr: 8.6e-05, average MSE (log10) loss: 3.8155986172812324, average MAPE: 3.8155986172812324                                                                                                                                                             \n",
      "Epoch 464/1000, lr: 8.6e-05, average MSE (log10) loss: 3.815927673845875, average MAPE: 3.815927673845875                                                                                                                                                             \n",
      "Epoch 465/1000, lr: 6.9e-05, average MSE (log10) loss: 3.8121921023544, average MAPE: 3.8121921023544                                                                                                                                                             \n",
      "Epoch 466/1000, lr: 6.9e-05, average MSE (log10) loss: 3.8039552854031933, average MAPE: 3.8039552854031933                                                                                                                                                             \n",
      "Epoch 467/1000, lr: 6.9e-05, average MSE (log10) loss: 3.806357849860678, average MAPE: 3.806357849860678                                                                                                                                                             \n",
      "Epoch 468/1000, lr: 6.9e-05, average MSE (log10) loss: 3.805268166016559, average MAPE: 3.805268166016559                                                                                                                                                             \n",
      "Epoch 469/1000, lr: 6.9e-05, average MSE (log10) loss: 3.8063497728231, average MAPE: 3.8063497728231                                                                                                                                                             \n",
      "Epoch 470/1000, lr: 6.9e-05, average MSE (log10) loss: 3.804709702121968, average MAPE: 3.804709702121968                                                                                                                                                             \n",
      "Epoch 471/1000, lr: 6.9e-05, average MSE (log10) loss: 3.8056653324438603, average MAPE: 3.8056653324438603                                                                                                                                                             \n",
      "Epoch 472/1000, lr: 6.9e-05, average MSE (log10) loss: 3.8057685433601844, average MAPE: 3.8057685433601844                                                                                                                                                             \n",
      "Epoch 473/1000, lr: 6.9e-05, average MSE (log10) loss: 3.8054355884084896, average MAPE: 3.8054355884084896                                                                                                                                                             \n",
      "Epoch 474/1000, lr: 6.9e-05, average MSE (log10) loss: 3.8055943810209936, average MAPE: 3.8055943810209936                                                                                                                                                             \n",
      "Epoch 475/1000, lr: 6.9e-05, average MSE (log10) loss: 3.8046782114067854, average MAPE: 3.8046782114067854                                                                                                                                                             \n",
      "Epoch 476/1000, lr: 6.9e-05, average MSE (log10) loss: 3.8074511985389554, average MAPE: 3.8074511985389554                                                                                                                                                             \n",
      "Epoch 477/1000, lr: 6.9e-05, average MSE (log10) loss: 3.803584637933848, average MAPE: 3.803584637933848                                                                                                                                                             \n",
      "Epoch 478/1000, lr: 6.9e-05, average MSE (log10) loss: 3.8069522361366115, average MAPE: 3.8069522361366115                                                                                                                                                             \n",
      "Epoch 479/1000, lr: 6.9e-05, average MSE (log10) loss: 3.8040441727151677, average MAPE: 3.8040441727151677                                                                                                                                                             \n",
      "Epoch 480/1000, lr: 6.9e-05, average MSE (log10) loss: 3.80469955814128, average MAPE: 3.80469955814128                                                                                                                                                             \n",
      "Epoch 481/1000, lr: 6.9e-05, average MSE (log10) loss: 3.802486683397877, average MAPE: 3.802486683397877                                                                                                                                                             \n",
      "Epoch 482/1000, lr: 6.9e-05, average MSE (log10) loss: 3.8022041019128294, average MAPE: 3.8022041019128294                                                                                                                                                             \n",
      "Epoch 483/1000, lr: 6.9e-05, average MSE (log10) loss: 3.7988376364416006, average MAPE: 3.7988376364416006                                                                                                                                                             \n",
      "Epoch 484/1000, lr: 6.9e-05, average MSE (log10) loss: 3.800418066491886, average MAPE: 3.800418066491886                                                                                                                                                             \n",
      "Epoch 485/1000, lr: 5.5e-05, average MSE (log10) loss: 3.8019268395949384, average MAPE: 3.8019268395949384                                                                                                                                                             \n",
      "Epoch 486/1000, lr: 5.5e-05, average MSE (log10) loss: 3.79698682123301, average MAPE: 3.79698682123301                                                                                                                                                             \n",
      "Epoch 487/1000, lr: 5.5e-05, average MSE (log10) loss: 3.795925423563743, average MAPE: 3.795925423563743                                                                                                                                                             \n",
      "Epoch 488/1000, lr: 5.5e-05, average MSE (log10) loss: 3.7983775051272644, average MAPE: 3.7983775051272644                                                                                                                                                             \n",
      "Epoch 489/1000, lr: 5.5e-05, average MSE (log10) loss: 3.7978403899134423, average MAPE: 3.7978403899134423                                                                                                                                                             \n",
      "Epoch 490/1000, lr: 5.5e-05, average MSE (log10) loss: 3.7967968785032933, average MAPE: 3.7967968785032933                                                                                                                                                             \n",
      "Epoch 491/1000, lr: 5.5e-05, average MSE (log10) loss: 3.7980656370824697, average MAPE: 3.7980656370824697                                                                                                                                                             \n",
      "Epoch 492/1000, lr: 5.5e-05, average MSE (log10) loss: 3.797086999854263, average MAPE: 3.797086999854263                                                                                                                                                             \n",
      "Epoch 493/1000, lr: 5.5e-05, average MSE (log10) loss: 3.7971305788779746, average MAPE: 3.7971305788779746                                                                                                                                                             \n",
      "Epoch 494/1000, lr: 5.5e-05, average MSE (log10) loss: 3.797008226355728, average MAPE: 3.797008226355728                                                                                                                                                             \n",
      "Epoch 495/1000, lr: 5.5e-05, average MSE (log10) loss: 3.793692729911026, average MAPE: 3.793692729911026                                                                                                                                                             \n",
      "Epoch 496/1000, lr: 5.5e-05, average MSE (log10) loss: 3.794720122278953, average MAPE: 3.794720122278953                                                                                                                                                             \n",
      "Epoch 497/1000, lr: 5.5e-05, average MSE (log10) loss: 3.7937935459370515, average MAPE: 3.7937935459370515                                                                                                                                                             \n",
      "Epoch 498/1000, lr: 5.5e-05, average MSE (log10) loss: 3.793470887748563, average MAPE: 3.793470887748563                                                                                                                                                             \n",
      "Epoch 499/1000, lr: 5.5e-05, average MSE (log10) loss: 3.7953774218656577, average MAPE: 3.7953774218656577                                                                                                                                                             \n",
      "Epoch 500/1000, lr: 5.5e-05, average MSE (log10) loss: 3.7942769556629417, average MAPE: 3.7942769556629417                                                                                                                                                             \n",
      "Epoch 501/1000, lr: 5.5e-05, average MSE (log10) loss: 3.7937884856243524, average MAPE: 3.7937884856243524                                                                                                                                                             \n",
      "Epoch 502/1000, lr: 5.5e-05, average MSE (log10) loss: 3.7949123810748664, average MAPE: 3.7949123810748664                                                                                                                                                             \n",
      "Epoch 503/1000, lr: 5.5e-05, average MSE (log10) loss: 3.7933830475320622, average MAPE: 3.7933830475320622                                                                                                                                                             \n",
      "Epoch 504/1000, lr: 5.5e-05, average MSE (log10) loss: 3.7905166061557067, average MAPE: 3.7905166061557067                                                                                                                                                             \n",
      "Epoch 505/1000, lr: 5.5e-05, average MSE (log10) loss: 3.7897238527025494, average MAPE: 3.7897238527025494                                                                                                                                                             \n",
      "Epoch 506/1000, lr: 4.4e-05, average MSE (log10) loss: 3.7904902390071324, average MAPE: 3.7904902390071324                                                                                                                                                             \n",
      "Epoch 507/1000, lr: 4.4e-05, average MSE (log10) loss: 3.7883152426505577, average MAPE: 3.7883152426505577                                                                                                                                                             \n",
      "Epoch 508/1000, lr: 4.4e-05, average MSE (log10) loss: 3.790167201295191, average MAPE: 3.790167201295191                                                                                                                                                             \n",
      "Epoch 509/1000, lr: 4.4e-05, average MSE (log10) loss: 3.7896782680433625, average MAPE: 3.7896782680433625                                                                                                                                                             \n",
      "Epoch 510/1000, lr: 4.4e-05, average MSE (log10) loss: 3.7884145542066925, average MAPE: 3.7884145542066925                                                                                                                                                             \n",
      "Epoch 511/1000, lr: 4.4e-05, average MSE (log10) loss: 3.7911095093707647, average MAPE: 3.7911095093707647                                                                                                                                                             \n",
      "Epoch 512/1000, lr: 4.4e-05, average MSE (log10) loss: 3.7898829898055717, average MAPE: 3.7898829898055717                                                                                                                                                             \n",
      "Epoch 513/1000, lr: 4.4e-05, average MSE (log10) loss: 3.7896353225318755, average MAPE: 3.7896353225318755                                                                                                                                                             \n",
      "Epoch 514/1000, lr: 4.4e-05, average MSE (log10) loss: 3.7892640211144273, average MAPE: 3.7892640211144273                                                                                                                                                             \n",
      "Epoch 515/1000, lr: 4.4e-05, average MSE (log10) loss: 3.7866204748348316, average MAPE: 3.7866204748348316                                                                                                                                                             \n",
      "Epoch 516/1000, lr: 4.4e-05, average MSE (log10) loss: 3.7865575323299487, average MAPE: 3.7865575323299487                                                                                                                                                             \n",
      "Epoch 517/1000, lr: 4.4e-05, average MSE (log10) loss: 3.787751937399105, average MAPE: 3.787751937399105                                                                                                                                                             \n",
      "Epoch 518/1000, lr: 4.4e-05, average MSE (log10) loss: 3.787433200952958, average MAPE: 3.787433200952958                                                                                                                                                             \n",
      "Epoch 519/1000, lr: 4.4e-05, average MSE (log10) loss: 3.7856007167271204, average MAPE: 3.7856007167271204                                                                                                                                                             \n",
      "Epoch 520/1000, lr: 4.4e-05, average MSE (log10) loss: 3.786373722309969, average MAPE: 3.786373722309969                                                                                                                                                             \n",
      "Epoch 521/1000, lr: 4.4e-05, average MSE (log10) loss: 3.787988399972721, average MAPE: 3.787988399972721                                                                                                                                                             \n",
      "Epoch 522/1000, lr: 4.4e-05, average MSE (log10) loss: 3.7852036125805912, average MAPE: 3.7852036125805912                                                                                                                                                             \n",
      "Epoch 523/1000, lr: 4.4e-05, average MSE (log10) loss: 3.788550579304598, average MAPE: 3.788550579304598                                                                                                                                                             \n",
      "Epoch 524/1000, lr: 4.4e-05, average MSE (log10) loss: 3.785332911355155, average MAPE: 3.785332911355155                                                                                                                                                             \n",
      "Epoch 525/1000, lr: 4.4e-05, average MSE (log10) loss: 3.7839668303119893, average MAPE: 3.7839668303119893                                                                                                                                                             \n",
      "Epoch 526/1000, lr: 3.5e-05, average MSE (log10) loss: 3.7834057224040127, average MAPE: 3.7834057224040127                                                                                                                                                             \n",
      "Epoch 527/1000, lr: 3.5e-05, average MSE (log10) loss: 3.781699068692266, average MAPE: 3.781699068692266                                                                                                                                                             \n",
      "Epoch 528/1000, lr: 3.5e-05, average MSE (log10) loss: 3.784398110058843, average MAPE: 3.784398110058843                                                                                                                                                             \n",
      "Epoch 529/1000, lr: 3.5e-05, average MSE (log10) loss: 3.782692221232823, average MAPE: 3.782692221232823                                                                                                                                                             \n",
      "Epoch 530/1000, lr: 3.5e-05, average MSE (log10) loss: 3.780701160430908, average MAPE: 3.780701160430908                                                                                                                                                             \n",
      "Epoch 531/1000, lr: 3.5e-05, average MSE (log10) loss: 3.7791223302179455, average MAPE: 3.7791223302179455                                                                                                                                                             \n",
      "Epoch 532/1000, lr: 3.5e-05, average MSE (log10) loss: 3.7825490980732197, average MAPE: 3.7825490980732197                                                                                                                                                             \n",
      "Epoch 533/1000, lr: 3.5e-05, average MSE (log10) loss: 3.780580269560522, average MAPE: 3.780580269560522                                                                                                                                                             \n",
      "Epoch 534/1000, lr: 3.5e-05, average MSE (log10) loss: 3.7810224357916384, average MAPE: 3.7810224357916384                                                                                                                                                             \n",
      "Epoch 535/1000, lr: 3.5e-05, average MSE (log10) loss: 3.7810814585004535, average MAPE: 3.7810814585004535                                                                                                                                                             \n",
      "Epoch 536/1000, lr: 3.5e-05, average MSE (log10) loss: 3.7799809261244173, average MAPE: 3.7799809261244173                                                                                                                                                             \n",
      "Epoch 537/1000, lr: 3.5e-05, average MSE (log10) loss: 3.7820048847976997, average MAPE: 3.7820048847976997                                                                                                                                                             \n",
      "Epoch 538/1000, lr: 3.5e-05, average MSE (log10) loss: 3.7829714210665957, average MAPE: 3.7829714210665957                                                                                                                                                             \n",
      "Epoch 539/1000, lr: 3.5e-05, average MSE (log10) loss: 3.779492849233199, average MAPE: 3.779492849233199                                                                                                                                                             \n",
      "Epoch 540/1000, lr: 3.5e-05, average MSE (log10) loss: 3.7782496150659055, average MAPE: 3.7782496150659055                                                                                                                                                             \n",
      "Epoch 541/1000, lr: 3.5e-05, average MSE (log10) loss: 3.778510249390894, average MAPE: 3.778510249390894                                                                                                                                                             \n",
      "Epoch 542/1000, lr: 3.5e-05, average MSE (log10) loss: 3.7794862659610047, average MAPE: 3.7794862659610047                                                                                                                                                             \n",
      "Epoch 543/1000, lr: 3.5e-05, average MSE (log10) loss: 3.7791630443261592, average MAPE: 3.7791630443261592                                                                                                                                                             \n",
      "Epoch 544/1000, lr: 3.5e-05, average MSE (log10) loss: 3.779420075124624, average MAPE: 3.779420075124624                                                                                                                                                             \n",
      "Epoch 545/1000, lr: 3.5e-05, average MSE (log10) loss: 3.7785575915356073, average MAPE: 3.7785575915356073                                                                                                                                                             \n",
      "Epoch 546/1000, lr: 3.5e-05, average MSE (log10) loss: 3.7798644484305868, average MAPE: 3.7798644484305868                                                                                                                                                             \n",
      "Epoch 547/1000, lr: 2.8e-05, average MSE (log10) loss: 3.7769601140703473, average MAPE: 3.7769601140703473                                                                                                                                                             \n",
      "Epoch 548/1000, lr: 2.8e-05, average MSE (log10) loss: 3.7764340361770317, average MAPE: 3.7764340361770317                                                                                                                                                             \n",
      "Epoch 549/1000, lr: 2.8e-05, average MSE (log10) loss: 3.7749585579852667, average MAPE: 3.7749585579852667                                                                                                                                                             \n",
      "Epoch 550/1000, lr: 2.8e-05, average MSE (log10) loss: 3.7764308004963154, average MAPE: 3.7764308004963154                                                                                                                                                             \n",
      "Epoch 551/1000, lr: 2.8e-05, average MSE (log10) loss: 3.7773888140308616, average MAPE: 3.7773888140308616                                                                                                                                                             \n",
      "Epoch 552/1000, lr: 2.8e-05, average MSE (log10) loss: 3.777529912092248, average MAPE: 3.777529912092248                                                                                                                                                             \n",
      "Epoch 553/1000, lr: 2.8e-05, average MSE (log10) loss: 3.7754365181436342, average MAPE: 3.7754365181436342                                                                                                                                                             \n",
      "Epoch 554/1000, lr: 2.8e-05, average MSE (log10) loss: 3.7739586898258755, average MAPE: 3.7739586898258755                                                                                                                                                             \n",
      "Epoch 555/1000, lr: 2.8e-05, average MSE (log10) loss: 3.7753055222180425, average MAPE: 3.7753055222180425                                                                                                                                                             \n",
      "Epoch 556/1000, lr: 2.8e-05, average MSE (log10) loss: 3.7751740397239217, average MAPE: 3.7751740397239217                                                                                                                                                             \n",
      "Epoch 557/1000, lr: 2.8e-05, average MSE (log10) loss: 3.7752811042629943, average MAPE: 3.7752811042629943                                                                                                                                                             \n",
      "Epoch 558/1000, lr: 2.8e-05, average MSE (log10) loss: 3.7736369658489615, average MAPE: 3.7736369658489615                                                                                                                                                             \n",
      "Epoch 559/1000, lr: 2.8e-05, average MSE (log10) loss: 3.774256385102564, average MAPE: 3.774256385102564                                                                                                                                                             \n",
      "Epoch 560/1000, lr: 2.8e-05, average MSE (log10) loss: 3.7754017547685272, average MAPE: 3.7754017547685272                                                                                                                                                             \n",
      "Epoch 561/1000, lr: 2.8e-05, average MSE (log10) loss: 3.775372486698384, average MAPE: 3.775372486698384                                                                                                                                                             \n",
      "Epoch 562/1000, lr: 2.8e-05, average MSE (log10) loss: 3.775084167597245, average MAPE: 3.775084167597245                                                                                                                                                             \n",
      "Epoch 563/1000, lr: 2.8e-05, average MSE (log10) loss: 3.7737695168475716, average MAPE: 3.7737695168475716                                                                                                                                                             \n",
      "Epoch 564/1000, lr: 2.8e-05, average MSE (log10) loss: 3.773480984629417, average MAPE: 3.773480984629417                                                                                                                                                             \n",
      "Epoch 565/1000, lr: 2.8e-05, average MSE (log10) loss: 3.773549183047548, average MAPE: 3.773549183047548                                                                                                                                                             \n",
      "Epoch 566/1000, lr: 2.8e-05, average MSE (log10) loss: 3.77333830911286, average MAPE: 3.77333830911286                                                                                                                                                             \n",
      "Epoch 567/1000, lr: 2.3e-05, average MSE (log10) loss: 3.7745558213214485, average MAPE: 3.7745558213214485                                                                                                                                                             \n",
      "Epoch 568/1000, lr: 2.3e-05, average MSE (log10) loss: 3.771015431929608, average MAPE: 3.771015431929608                                                                                                                                                             \n",
      "Epoch 569/1000, lr: 2.3e-05, average MSE (log10) loss: 3.7714203951310137, average MAPE: 3.7714203951310137                                                                                                                                                             \n",
      "Epoch 570/1000, lr: 2.3e-05, average MSE (log10) loss: 3.772105127451371, average MAPE: 3.772105127451371                                                                                                                                                             \n",
      "Epoch 571/1000, lr: 2.3e-05, average MSE (log10) loss: 3.771190901191867, average MAPE: 3.771190901191867                                                                                                                                                             \n",
      "Epoch 572/1000, lr: 2.3e-05, average MSE (log10) loss: 3.7722519932960976, average MAPE: 3.7722519932960976                                                                                                                                                             \n",
      "Epoch 573/1000, lr: 2.3e-05, average MSE (log10) loss: 3.7723147119794573, average MAPE: 3.7723147119794573                                                                                                                                                             \n",
      "Epoch 574/1000, lr: 2.3e-05, average MSE (log10) loss: 3.7711438033045557, average MAPE: 3.7711438033045557                                                                                                                                                             \n",
      "Epoch 575/1000, lr: 2.3e-05, average MSE (log10) loss: 3.770511699209408, average MAPE: 3.770511699209408                                                                                                                                                             \n",
      "Epoch 576/1000, lr: 2.3e-05, average MSE (log10) loss: 3.7704144409724645, average MAPE: 3.7704144409724645                                                                                                                                                             \n",
      "Epoch 577/1000, lr: 2.3e-05, average MSE (log10) loss: 3.7709803629894645, average MAPE: 3.7709803629894645                                                                                                                                                             \n",
      "Epoch 578/1000, lr: 2.3e-05, average MSE (log10) loss: 3.7704964160919188, average MAPE: 3.7704964160919188                                                                                                                                                             \n",
      "Epoch 579/1000, lr: 2.3e-05, average MSE (log10) loss: 3.771155682388617, average MAPE: 3.771155682388617                                                                                                                                                             \n",
      "Epoch 580/1000, lr: 2.3e-05, average MSE (log10) loss: 3.7698051004993673, average MAPE: 3.7698051004993673                                                                                                                                                             \n",
      "Epoch 581/1000, lr: 2.3e-05, average MSE (log10) loss: 3.7685652460370744, average MAPE: 3.7685652460370744                                                                                                                                                             \n",
      "Epoch 582/1000, lr: 2.3e-05, average MSE (log10) loss: 3.768655168766878, average MAPE: 3.768655168766878                                                                                                                                                             \n",
      "Epoch 583/1000, lr: 2.3e-05, average MSE (log10) loss: 3.7704087130877437, average MAPE: 3.7704087130877437                                                                                                                                                             \n",
      "Epoch 584/1000, lr: 2.3e-05, average MSE (log10) loss: 3.7703707033274125, average MAPE: 3.7703707033274125                                                                                                                                                             \n",
      "Epoch 585/1000, lr: 2.3e-05, average MSE (log10) loss: 3.770054899916357, average MAPE: 3.770054899916357                                                                                                                                                             \n",
      "Epoch 586/1000, lr: 2.3e-05, average MSE (log10) loss: 3.769045859940198, average MAPE: 3.769045859940198                                                                                                                                                             \n",
      "Epoch 587/1000, lr: 1.8e-05, average MSE (log10) loss: 3.770208637081847, average MAPE: 3.770208637081847                                                                                                                                                             \n",
      "Epoch 588/1000, lr: 1.8e-05, average MSE (log10) loss: 3.768132364506624, average MAPE: 3.768132364506624                                                                                                                                                             \n",
      "Epoch 589/1000, lr: 1.8e-05, average MSE (log10) loss: 3.76781103756963, average MAPE: 3.76781103756963                                                                                                                                                             \n",
      "Epoch 590/1000, lr: 1.8e-05, average MSE (log10) loss: 3.7679148771324935, average MAPE: 3.7679148771324935                                                                                                                                                             \n",
      "Epoch 591/1000, lr: 1.8e-05, average MSE (log10) loss: 3.768054585554162, average MAPE: 3.768054585554162                                                                                                                                                             \n",
      "Epoch 592/1000, lr: 1.8e-05, average MSE (log10) loss: 3.769022564012177, average MAPE: 3.769022564012177                                                                                                                                                             \n",
      "Epoch 593/1000, lr: 1.8e-05, average MSE (log10) loss: 3.7668507128345725, average MAPE: 3.7668507128345725                                                                                                                                                             \n",
      "Epoch 594/1000, lr: 1.8e-05, average MSE (log10) loss: 3.7665339995403677, average MAPE: 3.7665339995403677                                                                                                                                                             \n",
      "Epoch 595/1000, lr: 1.8e-05, average MSE (log10) loss: 3.7682818977200254, average MAPE: 3.7682818977200254                                                                                                                                                             \n",
      "Epoch 596/1000, lr: 1.8e-05, average MSE (log10) loss: 3.766528185046449, average MAPE: 3.766528185046449                                                                                                                                                             \n",
      "Epoch 597/1000, lr: 1.8e-05, average MSE (log10) loss: 3.765406133690659, average MAPE: 3.765406133690659                                                                                                                                                             \n",
      "Epoch 598/1000, lr: 1.8e-05, average MSE (log10) loss: 3.7653386573402248, average MAPE: 3.7653386573402248                                                                                                                                                             \n",
      "Epoch 599/1000, lr: 1.8e-05, average MSE (log10) loss: 3.766817144471772, average MAPE: 3.766817144471772                                                                                                                                                             \n",
      "Epoch 600/1000, lr: 1.8e-05, average MSE (log10) loss: 3.7667566912514823, average MAPE: 3.7667566912514823                                                                                                                                                             \n",
      "Epoch 601/1000, lr: 1.8e-05, average MSE (log10) loss: 3.7662550575879155, average MAPE: 3.7662550575879155                                                                                                                                                             \n",
      "Epoch 602/1000, lr: 1.8e-05, average MSE (log10) loss: 3.7656817261053592, average MAPE: 3.7656817261053592                                                                                                                                                             \n",
      "Epoch 603/1000, lr: 1.8e-05, average MSE (log10) loss: 3.7661253111703057, average MAPE: 3.7661253111703057                                                                                                                                                             \n",
      "Epoch 604/1000, lr: 1.8e-05, average MSE (log10) loss: 3.76601006546799, average MAPE: 3.76601006546799                                                                                                                                                             \n",
      "Epoch 605/1000, lr: 1.8e-05, average MSE (log10) loss: 3.7651494610066316, average MAPE: 3.7651494610066316                                                                                                                                                             \n",
      "Epoch 606/1000, lr: 1.8e-05, average MSE (log10) loss: 3.7657971605962635, average MAPE: 3.7657971605962635                                                                                                                                                             \n",
      "Epoch 607/1000, lr: 1.8e-05, average MSE (log10) loss: 3.7661746842520576, average MAPE: 3.7661746842520576                                                                                                                                                             \n",
      "Epoch 608/1000, lr: 1.4e-05, average MSE (log10) loss: 3.764862298965454, average MAPE: 3.764862298965454                                                                                                                                                             \n",
      "Epoch 609/1000, lr: 1.4e-05, average MSE (log10) loss: 3.7648933138166156, average MAPE: 3.7648933138166156                                                                                                                                                             \n",
      "Epoch 610/1000, lr: 1.4e-05, average MSE (log10) loss: 3.7649843916601062, average MAPE: 3.7649843916601062                                                                                                                                                             \n",
      "Epoch 611/1000, lr: 1.4e-05, average MSE (log10) loss: 3.7640690696482757, average MAPE: 3.7640690696482757                                                                                                                                                             \n",
      "Epoch 612/1000, lr: 1.4e-05, average MSE (log10) loss: 3.7649655741088246, average MAPE: 3.7649655741088246                                                                                                                                                             \n",
      "Epoch 613/1000, lr: 1.4e-05, average MSE (log10) loss: 3.7646843569619315, average MAPE: 3.7646843569619315                                                                                                                                                             \n",
      "Epoch 614/1000, lr: 1.4e-05, average MSE (log10) loss: 3.7634142184744075, average MAPE: 3.7634142184744075                                                                                                                                                             \n",
      "Epoch 615/1000, lr: 1.4e-05, average MSE (log10) loss: 3.7636777624791984, average MAPE: 3.7636777624791984                                                                                                                                                             \n",
      "Epoch 616/1000, lr: 1.4e-05, average MSE (log10) loss: 3.7645375368546468, average MAPE: 3.7645375368546468                                                                                                                                                             \n",
      "Epoch 617/1000, lr: 1.4e-05, average MSE (log10) loss: 3.7633495817379075, average MAPE: 3.7633495817379075                                                                                                                                                             \n",
      "Epoch 618/1000, lr: 1.4e-05, average MSE (log10) loss: 3.763310615383849, average MAPE: 3.763310615383849                                                                                                                                                             \n",
      "Epoch 619/1000, lr: 1.4e-05, average MSE (log10) loss: 3.762638419015067, average MAPE: 3.762638419015067                                                                                                                                                             \n",
      "Epoch 620/1000, lr: 1.4e-05, average MSE (log10) loss: 3.76313354531113, average MAPE: 3.76313354531113                                                                                                                                                             \n",
      "Epoch 621/1000, lr: 1.4e-05, average MSE (log10) loss: 3.7627462873653488, average MAPE: 3.7627462873653488                                                                                                                                                             \n",
      "Epoch 622/1000, lr: 1.4e-05, average MSE (log10) loss: 3.763283552442278, average MAPE: 3.763283552442278                                                                                                                                                             \n",
      "Epoch 623/1000, lr: 1.4e-05, average MSE (log10) loss: 3.7607519519572357, average MAPE: 3.7607519519572357                                                                                                                                                             \n",
      "Epoch 624/1000, lr: 1.4e-05, average MSE (log10) loss: 3.7637277739388604, average MAPE: 3.7637277739388604                                                                                                                                                             \n",
      "Epoch 625/1000, lr: 1.4e-05, average MSE (log10) loss: 3.762562171780333, average MAPE: 3.762562171780333                                                                                                                                                             \n",
      "Epoch 626/1000, lr: 1.4e-05, average MSE (log10) loss: 3.764653352815278, average MAPE: 3.764653352815278                                                                                                                                                             \n",
      "Epoch 627/1000, lr: 1.4e-05, average MSE (log10) loss: 3.761812502024125, average MAPE: 3.761812502024125                                                                                                                                                             \n",
      "Epoch 628/1000, lr: 1.2e-05, average MSE (log10) loss: 3.763392028030084, average MAPE: 3.763392028030084                                                                                                                                                             \n",
      "Epoch 629/1000, lr: 1.2e-05, average MSE (log10) loss: 3.761620249067034, average MAPE: 3.761620249067034                                                                                                                                                             \n",
      "Epoch 630/1000, lr: 1.2e-05, average MSE (log10) loss: 3.7630561089029118, average MAPE: 3.7630561089029118                                                                                                                                                             \n",
      "Epoch 631/1000, lr: 1.2e-05, average MSE (log10) loss: 3.7614348703501177, average MAPE: 3.7614348703501177                                                                                                                                                             \n",
      "Epoch 632/1000, lr: 1.2e-05, average MSE (log10) loss: 3.760396853271796, average MAPE: 3.760396853271796                                                                                                                                                             \n",
      "Epoch 633/1000, lr: 1.2e-05, average MSE (log10) loss: 3.761553111368296, average MAPE: 3.761553111368296                                                                                                                                                             \n",
      "Epoch 634/1000, lr: 1.2e-05, average MSE (log10) loss: 3.760459232330322, average MAPE: 3.760459232330322                                                                                                                                                             \n",
      "Epoch 635/1000, lr: 1.2e-05, average MSE (log10) loss: 3.7610552505571015, average MAPE: 3.7610552505571015                                                                                                                                                             \n",
      "Epoch 636/1000, lr: 1.2e-05, average MSE (log10) loss: 3.7604874231377425, average MAPE: 3.7604874231377425                                                                                                                                                             \n",
      "Epoch 637/1000, lr: 1.2e-05, average MSE (log10) loss: 3.7606132614369296, average MAPE: 3.7606132614369296                                                                                                                                                             \n",
      "Epoch 638/1000, lr: 1.2e-05, average MSE (log10) loss: 3.7610180231989645, average MAPE: 3.7610180231989645                                                                                                                                                             \n",
      "Epoch 639/1000, lr: 1.2e-05, average MSE (log10) loss: 3.7611455304282053, average MAPE: 3.7611455304282053                                                                                                                                                             \n",
      "Epoch 640/1000, lr: 1.2e-05, average MSE (log10) loss: 3.7603182442334235, average MAPE: 3.7603182442334235                                                                                                                                                             \n",
      "Epoch 641/1000, lr: 1.2e-05, average MSE (log10) loss: 3.760591792087166, average MAPE: 3.760591792087166                                                                                                                                                             \n",
      "Epoch 642/1000, lr: 1.2e-05, average MSE (log10) loss: 3.7606000257998096, average MAPE: 3.7606000257998096                                                                                                                                                             \n",
      "Epoch 643/1000, lr: 1.2e-05, average MSE (log10) loss: 3.759518609728132, average MAPE: 3.759518609728132                                                                                                                                                             \n",
      "Epoch 644/1000, lr: 1.2e-05, average MSE (log10) loss: 3.759736390016517, average MAPE: 3.759736390016517                                                                                                                                                             \n",
      "Epoch 645/1000, lr: 1.2e-05, average MSE (log10) loss: 3.7615698921437164, average MAPE: 3.7615698921437164                                                                                                                                                             \n",
      "Epoch 646/1000, lr: 1.2e-05, average MSE (log10) loss: 3.7608377904308083, average MAPE: 3.7608377904308083                                                                                                                                                             \n",
      "Epoch 647/1000, lr: 1.2e-05, average MSE (log10) loss: 3.7608862438980415, average MAPE: 3.7608862438980415                                                                                                                                                             \n",
      "Epoch 648/1000, lr: 1.2e-05, average MSE (log10) loss: 3.7597738470349995, average MAPE: 3.7597738470349995                                                                                                                                                             \n",
      "Epoch 649/1000, lr: 1.0e-05, average MSE (log10) loss: 3.75901736142684, average MAPE: 3.75901736142684                                                                                                                                                             \n",
      "Epoch 650/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7599279919449162, average MAPE: 3.7599279919449162                                                                                                                                                             \n",
      "Epoch 651/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7592924643536003, average MAPE: 3.7592924643536003                                                                                                                                                             \n",
      "Epoch 652/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7589788242262236, average MAPE: 3.7589788242262236                                                                                                                                                             \n",
      "Epoch 653/1000, lr: 1.0e-05, average MSE (log10) loss: 3.75865136555263, average MAPE: 3.75865136555263                                                                                                                                                             \n",
      "Epoch 654/1000, lr: 1.0e-05, average MSE (log10) loss: 3.759827981676374, average MAPE: 3.759827981676374                                                                                                                                                             \n",
      "Epoch 655/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7598806673166703, average MAPE: 3.7598806673166703                                                                                                                                                             \n",
      "Epoch 656/1000, lr: 1.0e-05, average MSE (log10) loss: 3.760533213128849, average MAPE: 3.760533213128849                                                                                                                                                             \n",
      "Epoch 657/1000, lr: 1.0e-05, average MSE (log10) loss: 3.760075834819249, average MAPE: 3.760075834819249                                                                                                                                                             \n",
      "Epoch 658/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7589576915818816, average MAPE: 3.7589576915818816                                                                                                                                                             \n",
      "Epoch 659/1000, lr: 1.0e-05, average MSE (log10) loss: 3.760028773911145, average MAPE: 3.760028773911145                                                                                                                                                             \n",
      "Epoch 660/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7597218386980953, average MAPE: 3.7597218386980953                                                                                                                                                             \n",
      "Epoch 661/1000, lr: 1.0e-05, average MSE (log10) loss: 3.758758489453063, average MAPE: 3.758758489453063                                                                                                                                                             \n",
      "Epoch 662/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7599647901496107, average MAPE: 3.7599647901496107                                                                                                                                                             \n",
      "Epoch 663/1000, lr: 1.0e-05, average MSE (log10) loss: 3.758045716188392, average MAPE: 3.758045716188392                                                                                                                                                             \n",
      "Epoch 664/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7588851013962103, average MAPE: 3.7588851013962103                                                                                                                                                             \n",
      "Epoch 665/1000, lr: 1.0e-05, average MSE (log10) loss: 3.757965965660251, average MAPE: 3.757965965660251                                                                                                                                                             \n",
      "Epoch 666/1000, lr: 1.0e-05, average MSE (log10) loss: 3.758405321471545, average MAPE: 3.758405321471545                                                                                                                                                             \n",
      "Epoch 667/1000, lr: 1.0e-05, average MSE (log10) loss: 3.758737107685634, average MAPE: 3.758737107685634                                                                                                                                                             \n",
      "Epoch 668/1000, lr: 1.0e-05, average MSE (log10) loss: 3.759231538188701, average MAPE: 3.759231538188701                                                                                                                                                             \n",
      "Epoch 669/1000, lr: 1.0e-05, average MSE (log10) loss: 3.759098451964709, average MAPE: 3.759098451964709                                                                                                                                                             \n",
      "Epoch 670/1000, lr: 1.0e-05, average MSE (log10) loss: 3.757659911136238, average MAPE: 3.757659911136238                                                                                                                                                             \n",
      "Epoch 671/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7558700337701914, average MAPE: 3.7558700337701914                                                                                                                                                             \n",
      "Epoch 672/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7574323790413993, average MAPE: 3.7574323790413993                                                                                                                                                             \n",
      "Epoch 673/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7584581783839632, average MAPE: 3.7584581783839632                                                                                                                                                             \n",
      "Epoch 674/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7585238602696633, average MAPE: 3.7585238602696633                                                                                                                                                             \n",
      "Epoch 675/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7571296380490673, average MAPE: 3.7571296380490673                                                                                                                                                             \n",
      "Epoch 676/1000, lr: 1.0e-05, average MSE (log10) loss: 3.758222993539304, average MAPE: 3.758222993539304                                                                                                                                                             \n",
      "Epoch 677/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7583554803108683, average MAPE: 3.7583554803108683                                                                                                                                                             \n",
      "Epoch 678/1000, lr: 1.0e-05, average MSE (log10) loss: 3.756622844812821, average MAPE: 3.756622844812821                                                                                                                                                             \n",
      "Epoch 679/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7576746259416853, average MAPE: 3.7576746259416853                                                                                                                                                             \n",
      "Epoch 680/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7573543315031093, average MAPE: 3.7573543315031093                                                                                                                                                             \n",
      "Epoch 681/1000, lr: 1.0e-05, average MSE (log10) loss: 3.757278432651442, average MAPE: 3.757278432651442                                                                                                                                                             \n",
      "Epoch 682/1000, lr: 1.0e-05, average MSE (log10) loss: 3.757603172380097, average MAPE: 3.757603172380097                                                                                                                                                             \n",
      "Epoch 683/1000, lr: 1.0e-05, average MSE (log10) loss: 3.757343351597689, average MAPE: 3.757343351597689                                                                                                                                                             \n",
      "Epoch 684/1000, lr: 1.0e-05, average MSE (log10) loss: 3.755772943885959, average MAPE: 3.755772943885959                                                                                                                                                             \n",
      "Epoch 685/1000, lr: 1.0e-05, average MSE (log10) loss: 3.756064060756138, average MAPE: 3.756064060756138                                                                                                                                                             \n",
      "Epoch 686/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7585506624105025, average MAPE: 3.7585506624105025                                                                                                                                                             \n",
      "Epoch 687/1000, lr: 1.0e-05, average MSE (log10) loss: 3.756429575900642, average MAPE: 3.756429575900642                                                                                                                                                             \n",
      "Epoch 688/1000, lr: 1.0e-05, average MSE (log10) loss: 3.756565270131948, average MAPE: 3.756565270131948                                                                                                                                                             \n",
      "Epoch 689/1000, lr: 1.0e-05, average MSE (log10) loss: 3.756192918699615, average MAPE: 3.756192918699615                                                                                                                                                             \n",
      "Epoch 690/1000, lr: 1.0e-05, average MSE (log10) loss: 3.756152425493513, average MAPE: 3.756152425493513                                                                                                                                                             \n",
      "Epoch 691/1000, lr: 1.0e-05, average MSE (log10) loss: 3.75601101213572, average MAPE: 3.75601101213572                                                                                                                                                             \n",
      "Epoch 692/1000, lr: 1.0e-05, average MSE (log10) loss: 3.756189897109051, average MAPE: 3.756189897109051                                                                                                                                                             \n",
      "Epoch 693/1000, lr: 1.0e-05, average MSE (log10) loss: 3.756080166174441, average MAPE: 3.756080166174441                                                                                                                                                             \n",
      "Epoch 694/1000, lr: 1.0e-05, average MSE (log10) loss: 3.755168887547084, average MAPE: 3.755168887547084                                                                                                                                                             \n",
      "Epoch 695/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7560668332236156, average MAPE: 3.7560668332236156                                                                                                                                                             \n",
      "Epoch 696/1000, lr: 1.0e-05, average MSE (log10) loss: 3.755087462250067, average MAPE: 3.755087462250067                                                                                                                                                             \n",
      "Epoch 697/1000, lr: 1.0e-05, average MSE (log10) loss: 3.755979415348598, average MAPE: 3.755979415348598                                                                                                                                                             \n",
      "Epoch 698/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7576786080185247, average MAPE: 3.7576786080185247                                                                                                                                                             \n",
      "Epoch 699/1000, lr: 1.0e-05, average MSE (log10) loss: 3.757017520009255, average MAPE: 3.757017520009255                                                                                                                                                             \n",
      "Epoch 700/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7563252254408233, average MAPE: 3.7563252254408233                                                                                                                                                             \n",
      "Epoch 701/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7552378926958356, average MAPE: 3.7552378926958356                                                                                                                                                             \n",
      "Epoch 702/1000, lr: 1.0e-05, average MSE (log10) loss: 3.75657262802124, average MAPE: 3.75657262802124                                                                                                                                                             \n",
      "Epoch 703/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7547605767542, average MAPE: 3.7547605767542                                                                                                                                                             \n",
      "Epoch 704/1000, lr: 1.0e-05, average MSE (log10) loss: 3.75621386839419, average MAPE: 3.75621386839419                                                                                                                                                             \n",
      "Epoch 705/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7557096714876135, average MAPE: 3.7557096714876135                                                                                                                                                             \n",
      "Epoch 706/1000, lr: 1.0e-05, average MSE (log10) loss: 3.75569401955118, average MAPE: 3.75569401955118                                                                                                                                                             \n",
      "Epoch 707/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7567834659498565, average MAPE: 3.7567834659498565                                                                                                                                                             \n",
      "Epoch 708/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7550134960485964, average MAPE: 3.7550134960485964                                                                                                                                                             \n",
      "Epoch 709/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7551973391552362, average MAPE: 3.7551973391552362                                                                                                                                                             \n",
      "Epoch 710/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7543106312654455, average MAPE: 3.7543106312654455                                                                                                                                                             \n",
      "Epoch 711/1000, lr: 1.0e-05, average MSE (log10) loss: 3.755594106596343, average MAPE: 3.755594106596343                                                                                                                                                             \n",
      "Epoch 712/1000, lr: 1.0e-05, average MSE (log10) loss: 3.755178845658594, average MAPE: 3.755178845658594                                                                                                                                                             \n",
      "Epoch 713/1000, lr: 1.0e-05, average MSE (log10) loss: 3.755979463032314, average MAPE: 3.755979463032314                                                                                                                                                             \n",
      "Epoch 714/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7542887658488993, average MAPE: 3.7542887658488993                                                                                                                                                             \n",
      "Epoch 715/1000, lr: 1.0e-05, average MSE (log10) loss: 3.75442232209809, average MAPE: 3.75442232209809                                                                                                                                                             \n",
      "Epoch 716/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7541668852981256, average MAPE: 3.7541668852981256                                                                                                                                                             \n",
      "Epoch 717/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7560188575666777, average MAPE: 3.7560188575666777                                                                                                                                                             \n",
      "Epoch 718/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7548273942908463, average MAPE: 3.7548273942908463                                                                                                                                                             \n",
      "Epoch 719/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7537383352007185, average MAPE: 3.7537383352007185                                                                                                                                                             \n",
      "Epoch 720/1000, lr: 1.0e-05, average MSE (log10) loss: 3.753718293443018, average MAPE: 3.753718293443018                                                                                                                                                             \n",
      "Epoch 721/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7555909925577593, average MAPE: 3.7555909925577593                                                                                                                                                             \n",
      "Epoch 722/1000, lr: 1.0e-05, average MSE (log10) loss: 3.755292883697821, average MAPE: 3.755292883697821                                                                                                                                                             \n",
      "Epoch 723/1000, lr: 1.0e-05, average MSE (log10) loss: 3.753899358243358, average MAPE: 3.753899358243358                                                                                                                                                             \n",
      "Epoch 724/1000, lr: 1.0e-05, average MSE (log10) loss: 3.753103490751617, average MAPE: 3.753103490751617                                                                                                                                                             \n",
      "Epoch 725/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7540493254758873, average MAPE: 3.7540493254758873                                                                                                                                                             \n",
      "Epoch 726/1000, lr: 1.0e-05, average MSE (log10) loss: 3.752743965265702, average MAPE: 3.752743965265702                                                                                                                                                             \n",
      "Epoch 727/1000, lr: 1.0e-05, average MSE (log10) loss: 3.752449793718299, average MAPE: 3.752449793718299                                                                                                                                                             \n",
      "Epoch 728/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7526469571249828, average MAPE: 3.7526469571249828                                                                                                                                                             \n",
      "Epoch 729/1000, lr: 1.0e-05, average MSE (log10) loss: 3.752822038105556, average MAPE: 3.752822038105556                                                                                                                                                             \n",
      "Epoch 730/1000, lr: 1.0e-05, average MSE (log10) loss: 3.753684440924197, average MAPE: 3.753684440924197                                                                                                                                                             \n",
      "Epoch 731/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7522164013920998, average MAPE: 3.7522164013920998                                                                                                                                                             \n",
      "Epoch 732/1000, lr: 1.0e-05, average MSE (log10) loss: 3.753743214509925, average MAPE: 3.753743214509925                                                                                                                                                             \n",
      "Epoch 733/1000, lr: 1.0e-05, average MSE (log10) loss: 3.751952598532852, average MAPE: 3.751952598532852                                                                                                                                                             \n",
      "Epoch 734/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7548919395524627, average MAPE: 3.7548919395524627                                                                                                                                                             \n",
      "Epoch 735/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7514863228311346, average MAPE: 3.7514863228311346                                                                                                                                                             \n",
      "Epoch 736/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7520132658432943, average MAPE: 3.7520132658432943                                                                                                                                                             \n",
      "Epoch 737/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7520617154179785, average MAPE: 3.7520617154179785                                                                                                                                                             \n",
      "Epoch 738/1000, lr: 1.0e-05, average MSE (log10) loss: 3.752949118127628, average MAPE: 3.752949118127628                                                                                                                                                             \n",
      "Epoch 739/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7539689297578773, average MAPE: 3.7539689297578773                                                                                                                                                             \n",
      "Epoch 740/1000, lr: 1.0e-05, average MSE (log10) loss: 3.751923928941999, average MAPE: 3.751923928941999                                                                                                                                                             \n",
      "Epoch 741/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7531571485558333, average MAPE: 3.7531571485558333                                                                                                                                                             \n",
      "Epoch 742/1000, lr: 1.0e-05, average MSE (log10) loss: 3.754620341865384, average MAPE: 3.754620341865384                                                                                                                                                             \n",
      "Epoch 743/1000, lr: 1.0e-05, average MSE (log10) loss: 3.753172395667251, average MAPE: 3.753172395667251                                                                                                                                                             \n",
      "Epoch 744/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7511756322821794, average MAPE: 3.7511756322821794                                                                                                                                                             \n",
      "Epoch 745/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7543593864051665, average MAPE: 3.7543593864051665                                                                                                                                                             \n",
      "Epoch 746/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7515706947871617, average MAPE: 3.7515706947871617                                                                                                                                                             \n",
      "Epoch 747/1000, lr: 1.0e-05, average MSE (log10) loss: 3.753207708864796, average MAPE: 3.753207708864796                                                                                                                                                             \n",
      "Epoch 748/1000, lr: 1.0e-05, average MSE (log10) loss: 3.751846810749599, average MAPE: 3.751846810749599                                                                                                                                                             \n",
      "Epoch 749/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7524620085346454, average MAPE: 3.7524620085346454                                                                                                                                                             \n",
      "Epoch 750/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7502851135876716, average MAPE: 3.7502851135876716                                                                                                                                                             \n",
      "Epoch 751/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7508248095609704, average MAPE: 3.7508248095609704                                                                                                                                                             \n",
      "Epoch 752/1000, lr: 1.0e-05, average MSE (log10) loss: 3.752265988564005, average MAPE: 3.752265988564005                                                                                                                                                             \n",
      "Epoch 753/1000, lr: 1.0e-05, average MSE (log10) loss: 3.752752873362327, average MAPE: 3.752752873362327                                                                                                                                                             \n",
      "Epoch 754/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7528518890847966, average MAPE: 3.7528518890847966                                                                                                                                                             \n",
      "Epoch 755/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7517269640552753, average MAPE: 3.7517269640552753                                                                                                                                                             \n",
      "Epoch 756/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7507624412069513, average MAPE: 3.7507624412069513                                                                                                                                                             \n",
      "Epoch 757/1000, lr: 1.0e-05, average MSE (log10) loss: 3.751369214544491, average MAPE: 3.751369214544491                                                                                                                                                             \n",
      "Epoch 758/1000, lr: 1.0e-05, average MSE (log10) loss: 3.751208256702034, average MAPE: 3.751208256702034                                                                                                                                                             \n",
      "Epoch 759/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7532605969176, average MAPE: 3.7532605969176                                                                                                                                                             \n",
      "Epoch 760/1000, lr: 1.0e-05, average MSE (log10) loss: 3.751656503093486, average MAPE: 3.751656503093486                                                                                                                                                             \n",
      "Epoch 761/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7509361130850656, average MAPE: 3.7509361130850656                                                                                                                                                             \n",
      "Epoch 762/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7518857741842466, average MAPE: 3.7518857741842466                                                                                                                                                             \n",
      "Epoch 763/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7516149569530874, average MAPE: 3.7516149569530874                                                                                                                                                             \n",
      "Epoch 764/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7517043619739767, average MAPE: 3.7517043619739767                                                                                                                                                             \n",
      "Epoch 765/1000, lr: 1.0e-05, average MSE (log10) loss: 3.752823236037274, average MAPE: 3.752823236037274                                                                                                                                                             \n",
      "Epoch 766/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7506719365411874, average MAPE: 3.7506719365411874                                                                                                                                                             \n",
      "Epoch 767/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7511957071265396, average MAPE: 3.7511957071265396                                                                                                                                                             \n",
      "Epoch 768/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7505148556767676, average MAPE: 3.7505148556767676                                                                                                                                                             \n",
      "Epoch 769/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7508070731649594, average MAPE: 3.7508070731649594                                                                                                                                                             \n",
      "Epoch 770/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7506544074233696, average MAPE: 3.7506544074233696                                                                                                                                                             \n",
      "Epoch 771/1000, lr: 1.0e-05, average MSE (log10) loss: 3.749652500541843, average MAPE: 3.749652500541843                                                                                                                                                             \n",
      "Epoch 772/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7504400535505646, average MAPE: 3.7504400535505646                                                                                                                                                             \n",
      "Epoch 773/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7509389643766444, average MAPE: 3.7509389643766444                                                                                                                                                             \n",
      "Epoch 774/1000, lr: 1.0e-05, average MSE (log10) loss: 3.749777465937089, average MAPE: 3.749777465937089                                                                                                                                                             \n",
      "Epoch 775/1000, lr: 1.0e-05, average MSE (log10) loss: 3.750082680643821, average MAPE: 3.750082680643821                                                                                                                                                             \n",
      "Epoch 776/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7495426508845116, average MAPE: 3.7495426508845116                                                                                                                                                             \n",
      "Epoch 777/1000, lr: 1.0e-05, average MSE (log10) loss: 3.749915037349779, average MAPE: 3.749915037349779                                                                                                                                                             \n",
      "Epoch 778/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7512025473069173, average MAPE: 3.7512025473069173                                                                                                                                                             \n",
      "Epoch 779/1000, lr: 1.0e-05, average MSE (log10) loss: 3.749794811132003, average MAPE: 3.749794811132003                                                                                                                                                             \n",
      "Epoch 780/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7488036165432055, average MAPE: 3.7488036165432055                                                                                                                                                             \n",
      "Epoch 781/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7480877156160317, average MAPE: 3.7480877156160317                                                                                                                                                             \n",
      "Epoch 782/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7503115751305405, average MAPE: 3.7503115751305405                                                                                                                                                             \n",
      "Epoch 783/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7517849562119463, average MAPE: 3.7517849562119463                                                                                                                                                             \n",
      "Epoch 784/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7503579363530997, average MAPE: 3.7503579363530997                                                                                                                                                             \n",
      "Epoch 785/1000, lr: 1.0e-05, average MSE (log10) loss: 3.749729058207298, average MAPE: 3.749729058207298                                                                                                                                                             \n",
      "Epoch 786/1000, lr: 1.0e-05, average MSE (log10) loss: 3.749471766608102, average MAPE: 3.749471766608102                                                                                                                                                             \n",
      "Epoch 787/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7497498852866036, average MAPE: 3.7497498852866036                                                                                                                                                             \n",
      "Epoch 788/1000, lr: 1.0e-05, average MSE (log10) loss: 3.748933103133221, average MAPE: 3.748933103133221                                                                                                                                                             \n",
      "Epoch 789/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7482676622818927, average MAPE: 3.7482676622818927                                                                                                                                                             \n",
      "Epoch 790/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7492409560145163, average MAPE: 3.7492409560145163                                                                                                                                                             \n",
      "Epoch 791/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7495247247267742, average MAPE: 3.7495247247267742                                                                                                                                                             \n",
      "Epoch 792/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7498396435562444, average MAPE: 3.7498396435562444                                                                                                                                                             \n",
      "Epoch 793/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7499752005752254, average MAPE: 3.7499752005752254                                                                                                                                                             \n",
      "Epoch 794/1000, lr: 1.0e-05, average MSE (log10) loss: 3.748408129750466, average MAPE: 3.748408129750466                                                                                                                                                             \n",
      "Epoch 795/1000, lr: 1.0e-05, average MSE (log10) loss: 3.748280358801083, average MAPE: 3.748280358801083                                                                                                                                                             \n",
      "Epoch 796/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7479386932995853, average MAPE: 3.7479386932995853                                                                                                                                                             \n",
      "Epoch 797/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7479582951993358, average MAPE: 3.7479582951993358                                                                                                                                                             \n",
      "Epoch 798/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7479470613051435, average MAPE: 3.7479470613051435                                                                                                                                                             \n",
      "Epoch 799/1000, lr: 1.0e-05, average MSE (log10) loss: 3.748555135726929, average MAPE: 3.748555135726929                                                                                                                                                             \n",
      "Epoch 800/1000, lr: 1.0e-05, average MSE (log10) loss: 3.749276112536995, average MAPE: 3.749276112536995                                                                                                                                                             \n",
      "Epoch 801/1000, lr: 1.0e-05, average MSE (log10) loss: 3.749711662409257, average MAPE: 3.749711662409257                                                                                                                                                             \n",
      "Epoch 802/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7482792066068065, average MAPE: 3.7482792066068065                                                                                                                                                             \n",
      "Epoch 803/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7481544650330836, average MAPE: 3.7481544650330836                                                                                                                                                             \n",
      "Epoch 804/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7490353525901328, average MAPE: 3.7490353525901328                                                                                                                                                             \n",
      "Epoch 805/1000, lr: 1.0e-05, average MSE (log10) loss: 3.74876624321451, average MAPE: 3.74876624321451                                                                                                                                                             \n",
      "Epoch 806/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7476049238321734, average MAPE: 3.7476049238321734                                                                                                                                                             \n",
      "Epoch 807/1000, lr: 1.0e-05, average MSE (log10) loss: 3.747172907420567, average MAPE: 3.747172907420567                                                                                                                                                             \n",
      "Epoch 808/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7470047026264424, average MAPE: 3.7470047026264424                                                                                                                                                             \n",
      "Epoch 809/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7475905603292037, average MAPE: 3.7475905603292037                                                                                                                                                             \n",
      "Epoch 810/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7468381628698233, average MAPE: 3.7468381628698233                                                                                                                                                             \n",
      "Epoch 811/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7483913480019084, average MAPE: 3.7483913480019084                                                                                                                                                             \n",
      "Epoch 812/1000, lr: 1.0e-05, average MSE (log10) loss: 3.747796118016146, average MAPE: 3.747796118016146                                                                                                                                                             \n",
      "Epoch 813/1000, lr: 1.0e-05, average MSE (log10) loss: 3.748606418103588, average MAPE: 3.748606418103588                                                                                                                                                             \n",
      "Epoch 814/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7465189748880814, average MAPE: 3.7465189748880814                                                                                                                                                             \n",
      "Epoch 815/1000, lr: 1.0e-05, average MSE (log10) loss: 3.746506269610658, average MAPE: 3.746506269610658                                                                                                                                                             \n",
      "Epoch 816/1000, lr: 1.0e-05, average MSE (log10) loss: 3.747744607925415, average MAPE: 3.747744607925415                                                                                                                                                             \n",
      "Epoch 817/1000, lr: 1.0e-05, average MSE (log10) loss: 3.747940680445457, average MAPE: 3.747940680445457                                                                                                                                                             \n",
      "Epoch 818/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7467899633913624, average MAPE: 3.7467899633913624                                                                                                                                                             \n",
      "Epoch 819/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7467779461218385, average MAPE: 3.7467779461218385                                                                                                                                                             \n",
      "Epoch 820/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7461189328407754, average MAPE: 3.7461189328407754                                                                                                                                                             \n",
      "Epoch 821/1000, lr: 1.0e-05, average MSE (log10) loss: 3.747988804992364, average MAPE: 3.747988804992364                                                                                                                                                             \n",
      "Epoch 822/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7470814782745983, average MAPE: 3.7470814782745983                                                                                                                                                             \n",
      "Epoch 823/1000, lr: 1.0e-05, average MSE (log10) loss: 3.746519944132591, average MAPE: 3.746519944132591                                                                                                                                                             \n",
      "Epoch 824/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7448618519062897, average MAPE: 3.7448618519062897                                                                                                                                                             \n",
      "Epoch 825/1000, lr: 1.0e-05, average MSE (log10) loss: 3.74793293719389, average MAPE: 3.74793293719389                                                                                                                                                             \n",
      "Epoch 826/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7461043036713892, average MAPE: 3.7461043036713892                                                                                                                                                             \n",
      "Epoch 827/1000, lr: 1.0e-05, average MSE (log10) loss: 3.746626959041673, average MAPE: 3.746626959041673                                                                                                                                                             \n",
      "Epoch 828/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7464581226815983, average MAPE: 3.7464581226815983                                                                                                                                                             \n",
      "Epoch 829/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7476808917765716, average MAPE: 3.7476808917765716                                                                                                                                                             \n",
      "Epoch 830/1000, lr: 1.0e-05, average MSE (log10) loss: 3.746339747370506, average MAPE: 3.746339747370506                                                                                                                                                             \n",
      "Epoch 831/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7471236569540842, average MAPE: 3.7471236569540842                                                                                                                                                             \n",
      "Epoch 832/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7451119870555645, average MAPE: 3.7451119870555645                                                                                                                                                             \n",
      "Epoch 833/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7445918920088785, average MAPE: 3.7445918920088785                                                                                                                                                             \n",
      "Epoch 834/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7447366879910837, average MAPE: 3.7447366879910837                                                                                                                                                             \n",
      "Epoch 835/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7474680832454137, average MAPE: 3.7474680832454137                                                                                                                                                             \n",
      "Epoch 836/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7469630416558712, average MAPE: 3.7469630416558712                                                                                                                                                             \n",
      "Epoch 837/1000, lr: 1.0e-05, average MSE (log10) loss: 3.746763896942139, average MAPE: 3.746763896942139                                                                                                                                                             \n",
      "Epoch 838/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7453353482849745, average MAPE: 3.7453353482849745                                                                                                                                                             \n",
      "Epoch 839/1000, lr: 1.0e-05, average MSE (log10) loss: 3.746055297462308, average MAPE: 3.746055297462308                                                                                                                                                             \n",
      "Epoch 840/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7444229174633414, average MAPE: 3.7444229174633414                                                                                                                                                             \n",
      "Epoch 841/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7443403847363532, average MAPE: 3.7443403847363532                                                                                                                                                             \n",
      "Epoch 842/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7454583849225727, average MAPE: 3.7454583849225727                                                                                                                                                             \n",
      "Epoch 843/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7450174458172856, average MAPE: 3.7450174458172856                                                                                                                                                             \n",
      "Epoch 844/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7456702339405914, average MAPE: 3.7456702339405914                                                                                                                                                             \n",
      "Epoch 845/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7438802407712353, average MAPE: 3.7438802407712353                                                                                                                                                             \n",
      "Epoch 846/1000, lr: 1.0e-05, average MSE (log10) loss: 3.745513896552884, average MAPE: 3.745513896552884                                                                                                                                                             \n",
      "Epoch 847/1000, lr: 1.0e-05, average MSE (log10) loss: 3.745304869632332, average MAPE: 3.745304869632332                                                                                                                                                             \n",
      "Epoch 848/1000, lr: 1.0e-05, average MSE (log10) loss: 3.74542337534379, average MAPE: 3.74542337534379                                                                                                                                                             \n",
      "Epoch 849/1000, lr: 1.0e-05, average MSE (log10) loss: 3.743777696453795, average MAPE: 3.743777696453795                                                                                                                                                             \n",
      "Epoch 850/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7435701292388295, average MAPE: 3.7435701292388295                                                                                                                                                             \n",
      "Epoch 851/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7438973008369913, average MAPE: 3.7438973008369913                                                                                                                                                             \n",
      "Epoch 852/1000, lr: 1.0e-05, average MSE (log10) loss: 3.746352758212965, average MAPE: 3.746352758212965                                                                                                                                                             \n",
      "Epoch 853/1000, lr: 1.0e-05, average MSE (log10) loss: 3.742907594174755, average MAPE: 3.742907594174755                                                                                                                                                             \n",
      "Epoch 854/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7449344732323473, average MAPE: 3.7449344732323473                                                                                                                                                             \n",
      "Epoch 855/1000, lr: 1.0e-05, average MSE (log10) loss: 3.746011752498393, average MAPE: 3.746011752498393                                                                                                                                                             \n",
      "Epoch 856/1000, lr: 1.0e-05, average MSE (log10) loss: 3.745348921600653, average MAPE: 3.745348921600653                                                                                                                                                             \n",
      "Epoch 857/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7445159600705518, average MAPE: 3.7445159600705518                                                                                                                                                             \n",
      "Epoch 858/1000, lr: 1.0e-05, average MSE (log10) loss: 3.742105753567754, average MAPE: 3.742105753567754                                                                                                                                                             \n",
      "Epoch 859/1000, lr: 1.0e-05, average MSE (log10) loss: 3.742562672556663, average MAPE: 3.742562672556663                                                                                                                                                             \n",
      "Epoch 860/1000, lr: 1.0e-05, average MSE (log10) loss: 3.74500370609517, average MAPE: 3.74500370609517                                                                                                                                                             \n",
      "Epoch 861/1000, lr: 1.0e-05, average MSE (log10) loss: 3.743719230379377, average MAPE: 3.743719230379377                                                                                                                                                             \n",
      "Epoch 862/1000, lr: 1.0e-05, average MSE (log10) loss: 3.744618139461595, average MAPE: 3.744618139461595                                                                                                                                                             \n",
      "Epoch 863/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7435340462898723, average MAPE: 3.7435340462898723                                                                                                                                                             \n",
      "Epoch 864/1000, lr: 1.0e-05, average MSE (log10) loss: 3.742873236597801, average MAPE: 3.742873236597801                                                                                                                                                             \n",
      "Epoch 865/1000, lr: 1.0e-05, average MSE (log10) loss: 3.744969248285099, average MAPE: 3.744969248285099                                                                                                                                                             \n",
      "Epoch 866/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7432685910439005, average MAPE: 3.7432685910439005                                                                                                                                                             \n",
      "Epoch 867/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7441427824448565, average MAPE: 3.7441427824448565                                                                                                                                                             \n",
      "Epoch 868/1000, lr: 1.0e-05, average MSE (log10) loss: 3.744338809227457, average MAPE: 3.744338809227457                                                                                                                                                             \n",
      "Epoch 869/1000, lr: 1.0e-05, average MSE (log10) loss: 3.744970127027862, average MAPE: 3.744970127027862                                                                                                                                                             \n",
      "Epoch 870/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7440052548233345, average MAPE: 3.7440052548233345                                                                                                                                                             \n",
      "Epoch 871/1000, lr: 1.0e-05, average MSE (log10) loss: 3.744069801058088, average MAPE: 3.744069801058088                                                                                                                                                             \n",
      "Epoch 872/1000, lr: 1.0e-05, average MSE (log10) loss: 3.742842349227594, average MAPE: 3.742842349227594                                                                                                                                                             \n",
      "Epoch 873/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7435035686103664, average MAPE: 3.7435035686103664                                                                                                                                                             \n",
      "Epoch 874/1000, lr: 1.0e-05, average MSE (log10) loss: 3.743384375864146, average MAPE: 3.743384375864146                                                                                                                                                             \n",
      "Epoch 875/1000, lr: 1.0e-05, average MSE (log10) loss: 3.743937010667762, average MAPE: 3.743937010667762                                                                                                                                                             \n",
      "Epoch 876/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7431509485050123, average MAPE: 3.7431509485050123                                                                                                                                                             \n",
      "Epoch 877/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7427041627922835, average MAPE: 3.7427041627922835                                                                                                                                                             \n",
      "Epoch 878/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7432876285241576, average MAPE: 3.7432876285241576                                                                                                                                                             \n",
      "Epoch 879/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7436213756094174, average MAPE: 3.7436213756094174                                                                                                                                                             \n",
      "Epoch 880/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7427079210475998, average MAPE: 3.7427079210475998                                                                                                                                                             \n",
      "Epoch 881/1000, lr: 1.0e-05, average MSE (log10) loss: 3.742884804278004, average MAPE: 3.742884804278004                                                                                                                                                             \n",
      "Epoch 882/1000, lr: 1.0e-05, average MSE (log10) loss: 3.742003615048467, average MAPE: 3.742003615048467                                                                                                                                                             \n",
      "Epoch 883/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7436955218412438, average MAPE: 3.7436955218412438                                                                                                                                                             \n",
      "Epoch 884/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7428754407532363, average MAPE: 3.7428754407532363                                                                                                                                                             \n",
      "Epoch 885/1000, lr: 1.0e-05, average MSE (log10) loss: 3.743246551435821, average MAPE: 3.743246551435821                                                                                                                                                             \n",
      "Epoch 886/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7424363428232623, average MAPE: 3.7424363428232623                                                                                                                                                             \n",
      "Epoch 887/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7419335112279777, average MAPE: 3.7419335112279777                                                                                                                                                             \n",
      "Epoch 888/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7417619014272883, average MAPE: 3.7417619014272883                                                                                                                                                             \n",
      "Epoch 889/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7418702407759064, average MAPE: 3.7418702407759064                                                                                                                                                             \n",
      "Epoch 890/1000, lr: 1.0e-05, average MSE (log10) loss: 3.74120992543746, average MAPE: 3.74120992543746                                                                                                                                                             \n",
      "Epoch 891/1000, lr: 1.0e-05, average MSE (log10) loss: 3.741646433849724, average MAPE: 3.741646433849724                                                                                                                                                             \n",
      "Epoch 892/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7425827892459167, average MAPE: 3.7425827892459167                                                                                                                                                             \n",
      "Epoch 893/1000, lr: 1.0e-05, average MSE (log10) loss: 3.742130323332183, average MAPE: 3.742130323332183                                                                                                                                                             \n",
      "Epoch 894/1000, lr: 1.0e-05, average MSE (log10) loss: 3.741776049866968, average MAPE: 3.741776049866968                                                                                                                                                             \n",
      "Epoch 895/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7426402821832774, average MAPE: 3.7426402821832774                                                                                                                                                             \n",
      "Epoch 896/1000, lr: 1.0e-05, average MSE (log10) loss: 3.741960486587213, average MAPE: 3.741960486587213                                                                                                                                                             \n",
      "Epoch 897/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7414403905673903, average MAPE: 3.7414403905673903                                                                                                                                                             \n",
      "Epoch 898/1000, lr: 1.0e-05, average MSE (log10) loss: 3.742734923654673, average MAPE: 3.742734923654673                                                                                                                                                             \n",
      "Epoch 899/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7434510513227814, average MAPE: 3.7434510513227814                                                                                                                                                             \n",
      "Epoch 900/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7419048134161503, average MAPE: 3.7419048134161503                                                                                                                                                             \n",
      "Epoch 901/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7412101307693795, average MAPE: 3.7412101307693795                                                                                                                                                             \n",
      "Epoch 902/1000, lr: 1.0e-05, average MSE (log10) loss: 3.741824347632272, average MAPE: 3.741824347632272                                                                                                                                                             \n",
      "Epoch 903/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7412844171329422, average MAPE: 3.7412844171329422                                                                                                                                                             \n",
      "Epoch 904/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7422176545980026, average MAPE: 3.7422176545980026                                                                                                                                                             \n",
      "Epoch 905/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7420544079371862, average MAPE: 3.7420544079371862                                                                                                                                                             \n",
      "Epoch 906/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7394541827999817, average MAPE: 3.7394541827999817                                                                                                                                                             \n",
      "Epoch 907/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7392930176793313, average MAPE: 3.7392930176793313                                                                                                                                                             \n",
      "Epoch 908/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7406008477113684, average MAPE: 3.7406008477113684                                                                                                                                                             \n",
      "Epoch 909/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7400495198308206, average MAPE: 3.7400495198308206                                                                                                                                                             \n",
      "Epoch 910/1000, lr: 1.0e-05, average MSE (log10) loss: 3.739475950902822, average MAPE: 3.739475950902822                                                                                                                                                             \n",
      "Epoch 911/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7418005378878845, average MAPE: 3.7418005378878845                                                                                                                                                             \n",
      "Epoch 912/1000, lr: 1.0e-05, average MSE (log10) loss: 3.742033099155037, average MAPE: 3.742033099155037                                                                                                                                                             \n",
      "Epoch 913/1000, lr: 1.0e-05, average MSE (log10) loss: 3.741033194989574, average MAPE: 3.741033194989574                                                                                                                                                             \n",
      "Epoch 914/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7411627584574174, average MAPE: 3.7411627584574174                                                                                                                                                             \n",
      "Epoch 915/1000, lr: 1.0e-05, average MSE (log10) loss: 3.74079267054188, average MAPE: 3.74079267054188                                                                                                                                                             \n",
      "Epoch 916/1000, lr: 1.0e-05, average MSE (log10) loss: 3.742347843792974, average MAPE: 3.742347843792974                                                                                                                                                             \n",
      "Epoch 917/1000, lr: 1.0e-05, average MSE (log10) loss: 3.740843810840529, average MAPE: 3.740843810840529                                                                                                                                                             \n",
      "Epoch 918/1000, lr: 1.0e-05, average MSE (log10) loss: 3.740644479284481, average MAPE: 3.740644479284481                                                                                                                                                             \n",
      "Epoch 919/1000, lr: 1.0e-05, average MSE (log10) loss: 3.740585285303544, average MAPE: 3.740585285303544                                                                                                                                                             \n",
      "Epoch 920/1000, lr: 1.0e-05, average MSE (log10) loss: 3.739929565118284, average MAPE: 3.739929565118284                                                                                                                                                             \n",
      "Epoch 921/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7400811720867546, average MAPE: 3.7400811720867546                                                                                                                                                             \n",
      "Epoch 922/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7389595420993103, average MAPE: 3.7389595420993103                                                                                                                                                             \n",
      "Epoch 923/1000, lr: 1.0e-05, average MSE (log10) loss: 3.740209366350758, average MAPE: 3.740209366350758                                                                                                                                                             \n",
      "Epoch 924/1000, lr: 1.0e-05, average MSE (log10) loss: 3.740448692866734, average MAPE: 3.740448692866734                                                                                                                                                             \n",
      "Epoch 925/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7399471973886294, average MAPE: 3.7399471973886294                                                                                                                                                             \n",
      "Epoch 926/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7410910012770673, average MAPE: 3.7410910012770673                                                                                                                                                             \n",
      "Epoch 927/1000, lr: 1.0e-05, average MSE (log10) loss: 3.739773955637095, average MAPE: 3.739773955637095                                                                                                                                                             \n",
      "Epoch 928/1000, lr: 1.0e-05, average MSE (log10) loss: 3.73826096009235, average MAPE: 3.73826096009235                                                                                                                                                             \n",
      "Epoch 929/1000, lr: 1.0e-05, average MSE (log10) loss: 3.741409359172899, average MAPE: 3.741409359172899                                                                                                                                                             \n",
      "Epoch 930/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7389457945920985, average MAPE: 3.7389457945920985                                                                                                                                                             \n",
      "Epoch 931/1000, lr: 1.0e-05, average MSE (log10) loss: 3.739881374398056, average MAPE: 3.739881374398056                                                                                                                                                             \n",
      "Epoch 932/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7390495903637944, average MAPE: 3.7390495903637944                                                                                                                                                             \n",
      "Epoch 933/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7385922305437984, average MAPE: 3.7385922305437984                                                                                                                                                             \n",
      "Epoch 934/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7393590284853566, average MAPE: 3.7393590284853566                                                                                                                                                             \n",
      "Epoch 935/1000, lr: 1.0e-05, average MSE (log10) loss: 3.740339386219881, average MAPE: 3.740339386219881                                                                                                                                                             \n",
      "Epoch 936/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7394814909720906, average MAPE: 3.7394814909720906                                                                                                                                                             \n",
      "Epoch 937/1000, lr: 1.0e-05, average MSE (log10) loss: 3.73959230695452, average MAPE: 3.73959230695452                                                                                                                                                             \n",
      "Epoch 938/1000, lr: 1.0e-05, average MSE (log10) loss: 3.740050326561441, average MAPE: 3.740050326561441                                                                                                                                                             \n",
      "Epoch 939/1000, lr: 1.0e-05, average MSE (log10) loss: 3.739951873312191, average MAPE: 3.739951873312191                                                                                                                                                             \n",
      "Epoch 940/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7376076970781598, average MAPE: 3.7376076970781598                                                                                                                                                             \n",
      "Epoch 941/1000, lr: 1.0e-05, average MSE (log10) loss: 3.739357208719059, average MAPE: 3.739357208719059                                                                                                                                                             \n",
      "Epoch 942/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7376833429141922, average MAPE: 3.7376833429141922                                                                                                                                                             \n",
      "Epoch 943/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7377740207983523, average MAPE: 3.7377740207983523                                                                                                                                                             \n",
      "Epoch 944/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7389092114506934, average MAPE: 3.7389092114506934                                                                                                                                                             \n",
      "Epoch 945/1000, lr: 1.0e-05, average MSE (log10) loss: 3.738406852800019, average MAPE: 3.738406852800019                                                                                                                                                             \n",
      "Epoch 946/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7392210425162804, average MAPE: 3.7392210425162804                                                                                                                                                             \n",
      "Epoch 947/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7390527579249166, average MAPE: 3.7390527579249166                                                                                                                                                             \n",
      "Epoch 948/1000, lr: 1.0e-05, average MSE (log10) loss: 3.736493086328312, average MAPE: 3.736493086328312                                                                                                                                                             \n",
      "Epoch 949/1000, lr: 1.0e-05, average MSE (log10) loss: 3.738417470698454, average MAPE: 3.738417470698454                                                                                                                                                             \n",
      "Epoch 950/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7370321351654674, average MAPE: 3.7370321351654674                                                                                                                                                             \n",
      "Epoch 951/1000, lr: 1.0e-05, average MSE (log10) loss: 3.737003703020057, average MAPE: 3.737003703020057                                                                                                                                                             \n",
      "Epoch 952/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7388303056055188, average MAPE: 3.7388303056055188                                                                                                                                                             \n",
      "Epoch 953/1000, lr: 1.0e-05, average MSE (log10) loss: 3.737573644093105, average MAPE: 3.737573644093105                                                                                                                                                             \n",
      "Epoch 954/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7371272233067727, average MAPE: 3.7371272233067727                                                                                                                                                             \n",
      "Epoch 955/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7366409399071516, average MAPE: 3.7366409399071516                                                                                                                                                             \n",
      "Epoch 956/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7370092100026655, average MAPE: 3.7370092100026655                                                                                                                                                             \n",
      "Epoch 957/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7377300174868835, average MAPE: 3.7377300174868835                                                                                                                                                             \n",
      "Epoch 958/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7383161583725286, average MAPE: 3.7383161583725286                                                                                                                                                             \n",
      "Epoch 959/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7366470998647263, average MAPE: 3.7366470998647263                                                                                                                                                             \n",
      "Epoch 960/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7366708609522608, average MAPE: 3.7366708609522608                                                                                                                                                             \n",
      "Epoch 961/1000, lr: 1.0e-05, average MSE (log10) loss: 3.738384639973543, average MAPE: 3.738384639973543                                                                                                                                                             \n",
      "Epoch 962/1000, lr: 1.0e-05, average MSE (log10) loss: 3.736607465938646, average MAPE: 3.736607465938646                                                                                                                                                             \n",
      "Epoch 963/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7368303522771718, average MAPE: 3.7368303522771718                                                                                                                                                             \n",
      "Epoch 964/1000, lr: 1.0e-05, average MSE (log10) loss: 3.736016868085277, average MAPE: 3.736016868085277                                                                                                                                                             \n",
      "Epoch 965/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7377845686309192, average MAPE: 3.7377845686309192                                                                                                                                                             \n",
      "Epoch 966/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7358243504349065, average MAPE: 3.7358243504349065                                                                                                                                                             \n",
      "Epoch 967/1000, lr: 1.0e-05, average MSE (log10) loss: 3.73737049492038, average MAPE: 3.73737049492038                                                                                                                                                             \n",
      "Epoch 968/1000, lr: 1.0e-05, average MSE (log10) loss: 3.737157279617932, average MAPE: 3.737157279617932                                                                                                                                                             \n",
      "Epoch 969/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7360530074761837, average MAPE: 3.7360530074761837                                                                                                                                                             \n",
      "Epoch 970/1000, lr: 1.0e-05, average MSE (log10) loss: 3.738089998400941, average MAPE: 3.738089998400941                                                                                                                                                             \n",
      "Epoch 971/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7362103053501676, average MAPE: 3.7362103053501676                                                                                                                                                             \n",
      "Epoch 972/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7371220608146825, average MAPE: 3.7371220608146825                                                                                                                                                             \n",
      "Epoch 973/1000, lr: 1.0e-05, average MSE (log10) loss: 3.736393215218369, average MAPE: 3.736393215218369                                                                                                                                                             \n",
      "Epoch 974/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7370031541707562, average MAPE: 3.7370031541707562                                                                                                                                                             \n",
      "Epoch 975/1000, lr: 1.0e-05, average MSE (log10) loss: 3.736839925026407, average MAPE: 3.736839925026407                                                                                                                                                             \n",
      "Epoch 976/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7359320115069954, average MAPE: 3.7359320115069954                                                                                                                                                             \n",
      "Epoch 977/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7368323939187187, average MAPE: 3.7368323939187187                                                                                                                                                             \n",
      "Epoch 978/1000, lr: 1.0e-05, average MSE (log10) loss: 3.735551016671317, average MAPE: 3.735551016671317                                                                                                                                                             \n",
      "Epoch 979/1000, lr: 1.0e-05, average MSE (log10) loss: 3.735102144552737, average MAPE: 3.735102144552737                                                                                                                                                             \n",
      "Epoch 980/1000, lr: 1.0e-05, average MSE (log10) loss: 3.73605120619949, average MAPE: 3.73605120619949                                                                                                                                                             \n",
      "Epoch 981/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7361494881766184, average MAPE: 3.7361494881766184                                                                                                                                                             \n",
      "Epoch 982/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7349032917801215, average MAPE: 3.7349032917801215                                                                                                                                                             \n",
      "Epoch 983/1000, lr: 1.0e-05, average MSE (log10) loss: 3.735982757685136, average MAPE: 3.735982757685136                                                                                                                                                             \n",
      "Epoch 984/1000, lr: 1.0e-05, average MSE (log10) loss: 3.735168645819839, average MAPE: 3.735168645819839                                                                                                                                                             \n",
      "Epoch 985/1000, lr: 1.0e-05, average MSE (log10) loss: 3.736549524385102, average MAPE: 3.736549524385102                                                                                                                                                             \n",
      "Epoch 986/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7351644506259842, average MAPE: 3.7351644506259842                                                                                                                                                             \n",
      "Epoch 987/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7349121142406854, average MAPE: 3.7349121142406854                                                                                                                                                             \n",
      "Epoch 988/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7348283047578774, average MAPE: 3.7348283047578774                                                                                                                                                             \n",
      "Epoch 989/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7356734343937466, average MAPE: 3.7356734343937466                                                                                                                                                             \n",
      "Epoch 990/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7342033960381333, average MAPE: 3.7342033960381333                                                                                                                                                             \n",
      "Epoch 991/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7351903059044664, average MAPE: 3.7351903059044664                                                                                                                                                             \n",
      "Epoch 992/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7362131644268426, average MAPE: 3.7362131644268426                                                                                                                                                             \n",
      "Epoch 993/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7363954602455607, average MAPE: 3.7363954602455607                                                                                                                                                             \n",
      "Epoch 994/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7367318416128352, average MAPE: 3.7367318416128352                                                                                                                                                             \n",
      "Epoch 995/1000, lr: 1.0e-05, average MSE (log10) loss: 3.734814199136228, average MAPE: 3.734814199136228                                                                                                                                                             \n",
      "Epoch 996/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7361954085680904, average MAPE: 3.7361954085680904                                                                                                                                                             \n",
      "Epoch 997/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7340648427301524, average MAPE: 3.7340648427301524                                                                                                                                                             \n",
      "Epoch 998/1000, lr: 1.0e-05, average MSE (log10) loss: 3.735265722080153, average MAPE: 3.735265722080153                                                                                                                                                             \n",
      "Epoch 999/1000, lr: 1.0e-05, average MSE (log10) loss: 3.735281329252282, average MAPE: 3.735281329252282                                                                                                                                                             \n",
      "Epoch 1000/1000, lr: 1.0e-05, average MSE (log10) loss: 3.7341470309666227, average MAPE: 3.7341470309666227                                                                                                                                                             \n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "ratio_losses=[]\n",
    "mse_per_minibatch_nn=[]\n",
    "mape_per_minibatch_nn=[]\n",
    "mse_per_minibatch_fit=[]\n",
    "mape_per_minibatch_fit=[]\n",
    "for epoch in range(epochs):\n",
    "    total_mse = 0.0\n",
    "    total_mape = 0.0\n",
    "    for batch_idx,el in enumerate(dataloader):\n",
    "        minibatch=el[:,:-3].to(device)\n",
    "        altitude=el[:,-2].to(device)\n",
    "        rho_target=el[:,-1].to(device)\n",
    "        delta_params = model(minibatch).to(device)\n",
    "\n",
    "        #Constructs the inputs for the compute_approximated_density function as corrections from the global fit:\n",
    "        params = best_global_fit*(1+delta_params)\n",
    "        rho_nn=tn.rho_approximation(h=altitude,\n",
    "                                                params=params,\n",
    "                                                backend='torch')\n",
    "        rho_fit=tn.rho_approximation(h=altitude,\n",
    "                                             params=best_global_fit,\n",
    "                                             backend='torch')\n",
    "\n",
    "        loss = criterion(rho_nn, rho_target)\n",
    "\n",
    "        #Computes the global fit loss:\n",
    "        loss_fit =  criterion(rho_fit, rho_target)\n",
    "\n",
    "        # Zeroes the gradient (necessary because of things)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Calling the step function on an Optimizer makes an update to its\n",
    "        # parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Perform a step in LR scheduler to update LR\n",
    "        scheduler.step(loss.item())\n",
    "\n",
    "        #We compute the logged quantities\n",
    "        mse_per_minibatch_nn.append(loss.item())\n",
    "        mape_per_minibatch_nn.append(tn.mean_absolute_percentage_error(rho_nn, rho_target).item())\n",
    "        total_mse+=mse_per_minibatch_nn[-1]\n",
    "        total_mape+=mape_per_minibatch_nn[-1]\n",
    "        \n",
    "        #Now the same but for the global fit:\n",
    "        mse_per_minibatch_fit.append(loss_fit.item())\n",
    "        mape_per_minibatch_fit.append(tn.mean_absolute_percentage_error(rho_fit, rho_target).item())\n",
    "\n",
    "        #Ratio of the loss between the NN and the fit (the lower, the more the NN is doing better than a global fit)\n",
    "        ratio_losses.append(loss.item()/loss_fit.item())\n",
    "        #Save the best model (this is wrong and should be done on the dataset):\n",
    "        if batch_idx>1:\n",
    "            if mse_per_minibatch_nn[-1]<min(mse_per_minibatch_nn[:-1]):    \n",
    "                #updating torch best model:\n",
    "                torch.save(model.state_dict(), f'../models/nrlmsise00_model_xxx.pyt')\n",
    "                best_loss=loss.item()\n",
    "                #print(f'Saving model - current best loss: {best_loss}\\n')\n",
    "        else:\n",
    "            best_loss=loss.item()\n",
    "        #Print every 10 minibatches:\n",
    "        if batch_idx%10:    \n",
    "            print(f'minibatch: {batch_idx}/{len(dataloader)}, ratio: {ratio_losses[-1]:.4e}, best loss till now: {best_loss:.4e}, loss RMSE (log10) & MAPE -----  NN: {loss.item():.10f}, {mape_per_minibatch_nn[-1]:.7f}; fit: {loss_fit.item():.10f}, {mape_per_minibatch_fit[-1]:.7f}', end='\\r')\n",
    "    #Print at the end of the epoch\n",
    "    curr_lr = scheduler.optimizer.param_groups[0]['lr']\n",
    "    print(f'Epoch {epoch + 1}/{epochs}, lr: {curr_lr:.1e}, average MSE (log10) loss: {total_mse / len(dataloader)}, average MAPE: {total_mape / len(dataloader)}                                                                                                                                                             ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_params = model(torch_data[:,:-3]).to(device)\n",
    "params = best_global_fit*(1+delta_params)\n",
    "rho_nn=tn.rho_approximation(h=torch_data[:,-2],params=params,backend='torch')\n",
    "rho_fit=tn.rho_approximation(h=torch_data[:,-2],params=best_global_fit,backend='torch')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([7.64500e+03, 2.64130e+04, 4.06470e+04, 4.90810e+04, 5.72110e+04,\n",
       "        7.10660e+04, 9.92010e+04, 1.13134e+05, 1.03492e+05, 8.40460e+04,\n",
       "        6.50050e+04, 4.75570e+04, 3.65600e+04, 2.81690e+04, 2.27910e+04,\n",
       "        1.85690e+04, 1.53900e+04, 1.29820e+04, 1.11430e+04, 9.65900e+03,\n",
       "        8.51100e+03, 7.53300e+03, 6.59300e+03, 5.89700e+03, 5.42100e+03,\n",
       "        4.88700e+03, 4.48700e+03, 4.00200e+03, 3.50700e+03, 3.02000e+03,\n",
       "        2.87500e+03, 2.59500e+03, 2.19800e+03, 1.99900e+03, 1.73000e+03,\n",
       "        1.54300e+03, 1.40000e+03, 1.22100e+03, 1.07700e+03, 9.33000e+02,\n",
       "        8.67000e+02, 7.99000e+02, 7.22000e+02, 6.26000e+02, 5.09000e+02,\n",
       "        4.84000e+02, 4.68000e+02, 4.05000e+02, 3.59000e+02, 3.49000e+02,\n",
       "        2.93000e+02, 2.94000e+02, 2.83000e+02, 2.28000e+02, 2.00000e+02,\n",
       "        1.67000e+02, 1.66000e+02, 1.41000e+02, 1.45000e+02, 1.29000e+02,\n",
       "        1.14000e+02, 9.50000e+01, 8.10000e+01, 7.80000e+01, 7.30000e+01,\n",
       "        6.00000e+01, 5.90000e+01, 7.40000e+01, 4.90000e+01, 4.20000e+01,\n",
       "        3.00000e+01, 2.40000e+01, 2.40000e+01, 1.10000e+01, 2.30000e+01,\n",
       "        9.00000e+00, 1.60000e+01, 7.00000e+00, 1.50000e+01, 1.40000e+01,\n",
       "        1.00000e+01, 6.00000e+00, 6.00000e+00, 7.00000e+00, 7.00000e+00,\n",
       "        1.00000e+00, 4.00000e+00, 3.00000e+00, 5.00000e+00, 4.00000e+00,\n",
       "        2.00000e+00, 0.00000e+00, 2.00000e+00, 1.00000e+00, 1.00000e+00,\n",
       "        3.00000e+00, 2.00000e+00, 7.00000e+00, 2.00000e+00, 5.00000e+00]),\n",
       " array([ 0.03778633,  0.15152147,  0.26525661,  0.37899174,  0.49272688,\n",
       "         0.60646202,  0.72019715,  0.83393229,  0.94766743,  1.06140256,\n",
       "         1.1751377 ,  1.28887284,  1.40260797,  1.51634311,  1.63007825,\n",
       "         1.74381338,  1.85754852,  1.97128366,  2.08501879,  2.19875393,\n",
       "         2.31248907,  2.4262242 ,  2.53995934,  2.65369448,  2.76742961,\n",
       "         2.88116475,  2.99489989,  3.10863502,  3.22237016,  3.3361053 ,\n",
       "         3.44984043,  3.56357557,  3.67731071,  3.79104584,  3.90478098,\n",
       "         4.01851612,  4.13225126,  4.24598639,  4.35972153,  4.47345667,\n",
       "         4.5871918 ,  4.70092694,  4.81466208,  4.92839721,  5.04213235,\n",
       "         5.15586749,  5.26960262,  5.38333776,  5.4970729 ,  5.61080803,\n",
       "         5.72454317,  5.83827831,  5.95201344,  6.06574858,  6.17948372,\n",
       "         6.29321885,  6.40695399,  6.52068913,  6.63442426,  6.7481594 ,\n",
       "         6.86189454,  6.97562967,  7.08936481,  7.20309995,  7.31683508,\n",
       "         7.43057022,  7.54430536,  7.65804049,  7.77177563,  7.88551077,\n",
       "         7.99924591,  8.11298104,  8.22671618,  8.34045132,  8.45418645,\n",
       "         8.56792159,  8.68165673,  8.79539186,  8.909127  ,  9.02286214,\n",
       "         9.13659727,  9.25033241,  9.36406755,  9.47780268,  9.59153782,\n",
       "         9.70527296,  9.81900809,  9.93274323, 10.04647837, 10.1602135 ,\n",
       "        10.27394864, 10.38768378, 10.50141891, 10.61515405, 10.72888919,\n",
       "        10.84262432, 10.95635946, 11.0700946 , 11.18382973, 11.29756487,\n",
       "        11.41130001]),\n",
       " <BarContainer object of 100 artists>)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = rho_nn.detach().numpy()\n",
    "gt = target_density\n",
    "plt.hist((predictions/gt),bins=100,alpha=0.5)\n",
    "plt.hist((rho_fit/gt),bins=100,alpha=0.5)\n",
    "\n",
    "#plt.hist(np.abs(predictions-gt)/np.abs(gt)*100, bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log10(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thermonets",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
